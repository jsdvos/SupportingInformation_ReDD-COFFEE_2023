{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import matplotlib\n",
    "\n",
    "from ase.io import read\n",
    "from pyiron import Project, ase_to_pyiron\n",
    "\n",
    "from molmod.units import *\n",
    "from molmod.constants import *\n",
    "\n",
    "from collections import namedtuple, Counter\n",
    "from dataclasses import dataclass # replaces namedtuple with mutable attributes\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project for rotational barriers characterization\n",
    "pr = Project('barriers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g16 job function\n",
    "def g16_job(pr, structure, name, jobtype='sp', lot='B3LYP', basis_set='6-311++G(d,p)', settings={'EmpiricalDispersion':['GD3'], 'int':['grid=ultrafine'], 'scf':['tight','maxcycle=5000']}, suffix=None, cores=9, run_time=60*60):\n",
    "    job = pr.create_job(pr.job_type.Gaussian, name, delete_existing_job=True)\n",
    "    job.structure = structure\n",
    "    job.input['jobtype'] = jobtype\n",
    "    job.input['lot'] = lot\n",
    "    job.input['basis_set'] = basis_set\n",
    "    \n",
    "    if not settings is None:\n",
    "        job.input['settings'] = settings\n",
    "        \n",
    "    if suffix is not None:\n",
    "        job.input['suffix'] = suffix\n",
    "        \n",
    "    job.executable.version = '2019_mpi' # to work in kirlia\n",
    "    \n",
    "    job.server.queue = 'kirlia'\n",
    "    job.server.cores = cores\n",
    "    job.server.run_time = run_time # in seconds\n",
    "    \n",
    "    job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g16 job function\n",
    "def g16_gic_job(pr, structure, name, jobtype='opt', lot='B3LYP', basis_set='6-311++G(d,p)', settings={'EmpiricalDispersion':['GD3'], 'int':['grid=ultrafine'], 'scf':['tight','maxcycle=5000'], 'geom':['addgic'], 'nosymm':[]}, suffix=None, run_time=2*60*60):\n",
    "    job = pr.create_job(pr.job_type.Gaussian, name, delete_existing_job=True)\n",
    "    job.structure = structure\n",
    "    job.input['jobtype'] = jobtype\n",
    "    job.input['lot'] = lot\n",
    "    job.input['basis_set'] = basis_set\n",
    "    \n",
    "    if not settings is None:\n",
    "        job.input['settings'] = settings\n",
    "        \n",
    "    if suffix is not None:\n",
    "        job.input['suffix'] = suffix\n",
    "        \n",
    "    job.executable.version = '2019_mpi' # to work in kirlia\n",
    "    \n",
    "    job.server.queue = 'kirlia'\n",
    "    job.server.cores = 9\n",
    "    job.server.run_time = run_time # in seconds\n",
    "    \n",
    "    job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaff job function\n",
    "def yaff_opt_job(pr, name, structure, ffs, ffpars):\n",
    "    job = pr.create_job(pr.job_type.Yaff, name, delete_existing_job=True)\n",
    "    \n",
    "    job.calc_minimize(max_iter=10000)\n",
    "\n",
    "    job.input['ffpars'] = ffpars\n",
    "    job.structure = structure\n",
    "    job.ffatypes = ffs.ffatypes\n",
    "    job.ffatype_ids = ffs.ffatype_ids\n",
    "    job.bonds = ffs.bonds\n",
    "    \n",
    "    job.executable.version = '2020'\n",
    "    job.server.queue = 'slaking'\n",
    "    job.server.cores = 1\n",
    "    job.server.run_time = 5*60*60 # in seconds\n",
    "\n",
    "    job.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaff job function\n",
    "def yaff_scan_job(pr, name, sinfo, ffpars):\n",
    "    job = pr.create_job(pr.job_type.Yaff, name, delete_existing_job=True)\n",
    "    job.structure = sinfo.ff.structure\n",
    "    job.input['ffpars'] = ffpars # separate to allow for varying ffpars\n",
    "    \n",
    "    job.ffatypes = sinfo.ff.ffatypes\n",
    "    job.ffatype_ids = sinfo.ff.ffatype_ids\n",
    "    job.bonds = sinfo.ff.bonds\n",
    "\n",
    "    job.calc_scan(np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step), adapt_structure=sinfo.adapt_structure)\n",
    "    job.executable.version = '2020'\n",
    "    job.server.queue = 'slaking'\n",
    "    job.server.cores = 1\n",
    "    job.server.run_time = 15*60 # in seconds   \n",
    "    job.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaff job function\n",
    "def yaff_scan_structures_job(pr, name, sinfo, ffpars, structures):\n",
    "    job = pr.create_job(pr.job_type.Yaff, name, delete_existing_job=True)\n",
    "    job.structure = sinfo.ff.structure\n",
    "    job.input['ffpars'] = ffpars # separate to allow for varying ffpars\n",
    "    \n",
    "    job.ffatypes = sinfo.ff.ffatypes\n",
    "    job.ffatype_ids = sinfo.ff.ffatype_ids\n",
    "    job.bonds = sinfo.ff.bonds\n",
    "\n",
    "    job.calc_scan(np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step),structures=structures)\n",
    "    job.executable.version = '2020'\n",
    "    job.server.queue = 'slaking'\n",
    "    job.server.cores = 1\n",
    "    job.server.run_time = 15*60 # in seconds   \n",
    "    job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''@dataclass\n",
    "class ff_object:\n",
    "    structure: object\n",
    "    ffpars: object\n",
    "    ffpars_nodih: object\n",
    "    ffpars_polysix: object\n",
    "    ffatypes: object\n",
    "    ffatype_ids: object\n",
    "    bonds : object'''\n",
    "        \n",
    "        \n",
    "class FFobject(object):\n",
    "    def __init__(self,block_name,structure,ffatypes,ffatype_ids,bonds,fnames,fn_ai,ffpars_nodih=None,ffpars_polysix=None):\n",
    "        self.block_name = block_name\n",
    "        self.structure = structure\n",
    "        self.ffatypes = ffatypes\n",
    "        self.ffatype_ids = ffatype_ids\n",
    "        self.bonds = bonds\n",
    "        self.fnames = fnames\n",
    "        self.ffpars = self._set_ffpars()\n",
    "        self.fn_ai = fn_ai\n",
    "        self.ffpars_nodih = ffpars_nodih\n",
    "        self.ffpars_polysix = ffpars_polysix\n",
    "        \n",
    "    def _set_ffpars(self):\n",
    "        ffpars = ''\n",
    "        for fn in self.fnames:\n",
    "            with open(fn,'r') as f:\n",
    "                ffpars+=f.read()\n",
    "        return ffpars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure info and rotation grid\n",
    "class Sinfo(object):\n",
    "    def __init__(self,pr,ff,indices,mask=None,range_min=0,range_max=90,range_step=1,degeneracy=None, fit_indices=None):\n",
    "        self.pr = pr\n",
    "        self.ff = FFobject(ff.block_name,ff.structure,ff.ffatypes,ff.ffatype_ids,ff.bonds,ff.fnames,ff.fn_ai,ffpars_nodih=ff.ffpars_nodih,ffpars_polysix=ff.ffpars_polysix) # create new object to avoid overwritten when using the same FFObject for difference sinfos\n",
    "        self.indices = indices\n",
    "        self.mask = mask\n",
    "        self.mask_indices = None \n",
    "        self.range_min = range_min\n",
    "        self.range_max = range_max\n",
    "        self.range_step = range_step\n",
    "        self.degeneracy = degeneracy\n",
    "        \n",
    "        self.fit_indices = fit_indices\n",
    "        \n",
    "        self._set_mask_indices()\n",
    "        self.adapt_structure = self._set_adapt_structure()\n",
    "        \n",
    "        \n",
    "    # Define function to identify mask for rotation\n",
    "    @staticmethod\n",
    "    def get_mask(structure,indices):\n",
    "        # Assume that we can define mask by taking all atoms in the direction of the dihedral\n",
    "        ref_vector = structure.positions[indices[2]] - structure.positions[indices[1]]\n",
    "        mask = np.array([np.dot(pos - structure.positions[indices[1]], ref_vector) >= 0 for pos in structure.positions],dtype=np.int)\n",
    "        return mask\n",
    "        \n",
    "    def _set_mask_indices(self):\n",
    "        if self.mask is None:\n",
    "            self.mask = self.get_mask(self.ff.structure,self.indices)\n",
    "        else:\n",
    "            if len(self.mask)<len(self.ff.structure):\n",
    "                self.mask_indices = copy.copy(self.mask)\n",
    "                self.mask = None\n",
    "            else:\n",
    "                assert len(self.mask)==len(self.ff.structure)\n",
    "                self.mask_indices=None\n",
    "                \n",
    "    def _set_adapt_structure(self):\n",
    "        \n",
    "        def adapt_structure(structure,angle,idx=self.indices,mask=self.mask,indices=self.mask_indices):\n",
    "            new_structure = structure.copy()\n",
    "            new_structure.set_dihedral(*idx,angle=angle,mask=mask,indices=indices) # angle in degrees\n",
    "            return new_structure\n",
    "        \n",
    "        return adapt_structure\n",
    "                \n",
    "    def get_sub_project_name(self,key,suffix=None):\n",
    "        if suffix is not None:\n",
    "            return 'barriers/{}/{}_{}_{}'.format(self.pr.name,key,\"_\".join([str(i) for i in self.indices]),suffix)\n",
    "        else:\n",
    "            return 'barriers/{}/{}_{}'.format(self.pr.name,key,\"_\".join([str(i) for i in self.indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICs check (only dihedral can change)\n",
    "\n",
    "from yaff import *\n",
    "from yaff.log import *\n",
    "import copy\n",
    "\n",
    "log.set_level(0)\n",
    "\n",
    "def get_ICs(system, ics):\n",
    "    num = 0\n",
    "    ICl = InternalCoordinateList(DeltaList(system))\n",
    "    for ic in ics:\n",
    "        ICl.add_ic(ic)\n",
    "        num+=1\n",
    "    ICl.dlist.forward()\n",
    "    ICl.forward()\n",
    "\n",
    "    values = np.zeros(num)\n",
    "    for n in range(num):\n",
    "        values[n] = ICl.ictab[n][-2]\n",
    "\n",
    "    return values\n",
    "\n",
    "# Define function to read dihedral ffatype sets to see whether they are correctly removed\n",
    "def read_dihedral_terms(ffpars):\n",
    "    dih_set = []\n",
    "    for line in ffpars.split('\\n'):\n",
    "        if line.startswith('TORSION:PARS'):\n",
    "            l = line.split()\n",
    "            dih_set.append(tuple((l[1],l[2],l[3],l[4])))\n",
    "    return set(dih_set)\n",
    "\n",
    "\n",
    "\n",
    "def write_ffpars_nodih(name,sinfo):\n",
    "    dih_values = []\n",
    "    dihedral_set = read_dihedral_terms(sinfo.ff.ffpars)\n",
    "\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    for n,val in enumerate(grid):\n",
    "        adapted_structure = sinfo.adapt_structure(sinfo.ff.structure,val)\n",
    "        system = System(sinfo.ff.structure.numbers, adapted_structure.positions, ffatypes=sinfo.ff.ffatypes, ffatype_ids=sinfo.ff.ffatype_ids, bonds=sinfo.ff.bonds)\n",
    "\n",
    "        dihs = []\n",
    "        dihs_angle = []\n",
    "        for dih in system.iter_dihedrals():\n",
    "            dihs.append([system.ffatypes[system.ffatype_ids[i]] for i in dih])\n",
    "            dihs_angle.append(DihedAngle(*dih))\n",
    "\n",
    "        dih_values.append(np.round(np.array(get_ICs(system, dihs_angle)),8))\n",
    "\n",
    "    dih_values = np.asarray(dih_values)\n",
    "\n",
    "    print(\"{} ICs\\n\".format(name))\n",
    "\n",
    "    # print out those that change during trajectory\n",
    "    dihedral_deviations = np.zeros(dih_values.shape[1])    \n",
    "    for n in range(len(dihedral_deviations)):\n",
    "        dihedral_deviations[n] = np.average(np.arccos(np.cos(dih_values[:,n]-dih_values[-1,n])))\n",
    "\n",
    "    print(\"Dihedrals:\")\n",
    "    degeneracy = 0\n",
    "    for n in range(len(dihedral_deviations)):\n",
    "        if dihedral_deviations[n] > 5e-1:\n",
    "            degeneracy += 1\n",
    "            print(dihs[n])#, dihedral_deviations[n])\n",
    "            if tuple(dihs[n]) in dihedral_set:\n",
    "                dihedral_set.remove(tuple(dihs[n]))\n",
    "            elif tuple(dihs[n][::-1]) in dihedral_set:\n",
    "                dihedral_set.remove(tuple(dihs[n][::-1]))\n",
    "                \n",
    "    sinfo.degeneracy = degeneracy\n",
    "    \n",
    "    # Making adapted force field parameter file\n",
    "    ffpars_reduced = ''\n",
    "    for line in sinfo.ff.ffpars.split('\\n'):\n",
    "        if line.startswith('TORSION:PARS'):\n",
    "            l = line.split()\n",
    "            dih = tuple((l[1],l[2],l[3],l[4]))\n",
    "            if dih in dihedral_set:\n",
    "                ffpars_reduced+=line+'\\n'\n",
    "            else:\n",
    "                print('Removed the following line: ', line)\n",
    "        else:\n",
    "            ffpars_reduced+=line+'\\n'\n",
    "            \n",
    "    sinfo.ff.ffpars_nodih = ffpars_reduced\n",
    "    print('\\n\\n')\n",
    "                \n",
    "\n",
    "def plot_IC_variations(name,sinfo):\n",
    "    print(sinfo.ff.block_name)\n",
    "    bond_values = []\n",
    "    bend_values = []\n",
    "    dih_values = []\n",
    "  \n",
    "    dihedral_set = read_dihedral_terms(sinfo.ff.ffpars)\n",
    "    if sinfo.ff.structure.cell.volume >0:\n",
    "        system = System(sinfo.ff.structure.numbers, sinfo.ff.structure.positions, ffatypes=sinfo.ff.ffatypes, ffatype_ids=sinfo.ff.ffatype_ids, bonds=sinfo.ff.bonds, rvecs=sinfo.ff.structure.cell.array)\n",
    "    else:\n",
    "        system = System(sinfo.ff.structure.numbers, sinfo.ff.structure.positions, ffatypes=sinfo.ff.ffatypes, ffatype_ids=sinfo.ff.ffatype_ids, bonds=sinfo.ff.bonds)\n",
    "    yaff_ff = ForceField.generate(system, sinfo.ff.fnames, rcut=12.0*angstrom, alpha_scale=3.2, gcut_scale=1.5, smooth_ei=True, tailcorrections=True)\n",
    "\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    for n,val in enumerate(grid):\n",
    "        adapted_structure = sinfo.adapt_structure(sinfo.ff.structure,val)\n",
    "        yaff_ff.update_pos(adapted_structure.positions)\n",
    "        #system = System(sinfo.ff.structure.numbers, adapted_structure.positions, ffatypes=sinfo.ff.ffatypes, ffatype_ids=sinfo.ff.ffatype_ids, bonds=sinfo.ff.bonds)\n",
    "\n",
    "        dihs = []\n",
    "        dihs_angle = []\n",
    "        for dih in yaff_ff.system.iter_dihedrals():\n",
    "            dihs.append([yaff_ff.system.ffatypes[yaff_ff.system.ffatype_ids[i]] for i in dih])\n",
    "            dihs_angle.append(DihedAngle(*dih))\n",
    "\n",
    "\n",
    "        bends = []\n",
    "        bend_angles = []\n",
    "        for bend in system.iter_angles():\n",
    "            bends.append([yaff_ff.system.ffatypes[yaff_ff.system.ffatype_ids[i]] for i in bend])\n",
    "            bend_angles.append(BendAngle(*bend))\n",
    "\n",
    "        bonds = []\n",
    "        bond_lengths = []\n",
    "        for bond in system.iter_bonds():\n",
    "            bonds.append([yaff_ff.system.ffatypes[yaff_ff.system.ffatype_ids[i]] for i in bond])\n",
    "            bond_lengths.append(Bond(*bond))\n",
    "\n",
    "        bond_values.append(np.array(get_ICs(yaff_ff.system, bond_lengths)))\n",
    "        bend_values.append(np.array(get_ICs(yaff_ff.system, bend_angles)))\n",
    "        dih_values.append(np.round(np.array(get_ICs(yaff_ff.system, dihs_angle)),8))\n",
    "\n",
    "    bond_values = np.asarray(bond_values)\n",
    "    bend_values = np.asarray(bend_values)\n",
    "    dih_values = np.asarray(dih_values)\n",
    "\n",
    "    print(\"{} ICs\\n\".format(name))\n",
    "\n",
    "    # print out those that change during trajectory\n",
    "    \n",
    "    #indx = np.where(bond_values[0,:]>10)[0]\n",
    "    #for i in indx:\n",
    "    #    print(bonds[i],bond_values[0,i], list(system.iter_bonds())[i])\n",
    "    \n",
    "    \n",
    "    bond_deviations = np.zeros(bond_values.shape[1])\n",
    "    for n in range(len(bond_deviations)):\n",
    "        bond_deviations[n] = np.sum(np.abs(bond_values[:,n] - np.average(bond_values[:,n])))\n",
    "\n",
    "    print(\"Bonds:\")\n",
    "    for n in range(len(bond_deviations)):\n",
    "        if not bond_deviations[n] < 1e-5:\n",
    "            print(bonds[n], bond_deviations[n])\n",
    "\n",
    "    bend_deviations = np.zeros(bend_values.shape[1])\n",
    "    for n in range(len(bend_deviations)):\n",
    "        bend_deviations[n] = np.sum(np.abs(bend_values[:,n] - np.average(bend_values[:,n])))\n",
    "\n",
    "    print(\"Bends:\")\n",
    "    for n in range(len(bend_deviations)):\n",
    "        if not bend_deviations[n] < 1e-5:\n",
    "            print(bends[n])#, bend_deviations[n])\n",
    "\n",
    "    dihedral_deviations = np.zeros(dih_values.shape[1])    \n",
    "    for n in range(len(dihedral_deviations)):\n",
    "        dihedral_deviations[n] = np.average(np.arccos(np.cos(dih_values[:,n]-dih_values[-1,n])))\n",
    "\n",
    "    print(\"Dihedrals:\")\n",
    "    for n in range(len(dihedral_deviations)):\n",
    "        if not dihedral_deviations[n] < 2e-1:\n",
    "            print(dihs[n], dihedral_deviations[n])\n",
    "            try:\n",
    "                assert tuple(dihs[n]) in dihedral_set or tuple(dihs[n][::-1]) in dihedral_set\n",
    "            except AssertionError:\n",
    "                print('There was no FF term for the following dihedral: ', tuple(dihs[n]))\n",
    "                \n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    # Plot trajectory of ICs\n",
    "    fig,ax = pt.subplots(1,3,figsize=(15,10))\n",
    "    for n in range(bond_values.shape[1]):\n",
    "        ax[0].plot(grid,bond_values[:,n])\n",
    "    ax[0].set_title('Bonds')\n",
    "\n",
    "    for n in range(bend_values.shape[1]):\n",
    "        ax[1].plot(grid,np.rad2deg(bend_values[:,n]))\n",
    "    ax[1].set_title('Bends')\n",
    "\n",
    "    for n in range(dih_values.shape[1]):\n",
    "        if not dihedral_deviations[n] < 2e-1:\n",
    "            ax[2].plot(grid,np.rad2deg(dih_values[:,n]),label=str(dihs[n]))\n",
    "    ax[2].legend(bbox_to_anchor=(1.1,.5), loc='center left',frameon=False)\n",
    "    ax[2].set_title('Dihedrals')\n",
    "    pt.show()\n",
    "\n",
    "def compare_structures(name,pr,ff,structures,log_bonds=True,log_bends=True,log_dihedrals=True,save_png=False):\n",
    "    bond_values = []\n",
    "    bend_values = []\n",
    "    dih_values = []\n",
    "  \n",
    "\n",
    "    for n,structure in enumerate(structures.values()):\n",
    "        system = System(structure.numbers, structure.positions, ffatypes=ff.ffatypes, ffatype_ids=ff.ffatype_ids, bonds=ff.bonds)\n",
    "\n",
    "        dihs = []\n",
    "        dihs_angle = []\n",
    "        for dih in system.iter_dihedrals():\n",
    "            dihs.append([system.ffatypes[system.ffatype_ids[i]] for i in dih])\n",
    "            dihs_angle.append(DihedAngle(*dih))\n",
    "\n",
    "\n",
    "        bends = []\n",
    "        bend_angles = []\n",
    "        for bend in system.iter_angles():\n",
    "            bends.append([system.ffatypes[system.ffatype_ids[i]] for i in bend])\n",
    "            bend_angles.append(BendAngle(*bend))\n",
    "\n",
    "        bonds = []\n",
    "        bond_lengths = []\n",
    "        for bond in system.iter_bonds():\n",
    "            bonds.append([system.ffatypes[system.ffatype_ids[i]] for i in bond])\n",
    "            bond_lengths.append(Bond(*bond))\n",
    "\n",
    "        bond_values.append(np.array(get_ICs(system, bond_lengths)))\n",
    "        bend_values.append(np.array(get_ICs(system, bend_angles)))\n",
    "        dih_values.append(np.round(np.array(get_ICs(system, dihs_angle)),8))\n",
    "\n",
    "    bond_values = np.asarray(bond_values)\n",
    "    bend_values = np.asarray(bend_values)\n",
    "    dih_values = np.asarray(dih_values)\n",
    "\n",
    "    print(\"{} ICs\\n\".format(name))\n",
    "\n",
    "    # print out those that have a large difference between reference (-1) and latest FF calculation (-2) \n",
    "    bond_deviations = np.zeros(bond_values.shape[1])\n",
    "    for n in range(len(bond_deviations)):\n",
    "        bond_deviations[n] = np.sum(np.abs(bond_values[-2,n] - bond_values[-1,n]))\n",
    "        \n",
    "    bond_deviations_old = np.zeros(bond_values.shape[1])\n",
    "    if len(structures)==3:\n",
    "        for n in range(len(bond_deviations_old)):\n",
    "            bond_deviations_old[n] = np.sum(np.abs(bond_values[0,n] - bond_values[-1,n]))\n",
    "\n",
    "    if log_bonds:\n",
    "        print(\"Bonds:\")\n",
    "        for n in range(len(bond_deviations)):\n",
    "            if not bond_deviations[n] < 1e-2:\n",
    "                print(bonds[n], bond_deviations[n])\n",
    "\n",
    "    bend_deviations = np.zeros(bend_values.shape[1])\n",
    "    for n in range(len(bend_deviations)):\n",
    "        bend_deviations[n] = np.sum(np.abs(bend_values[-2,n] - bend_values[-1,n]))\n",
    "        \n",
    "    bend_deviations_old = np.zeros(bend_values.shape[1])\n",
    "    if len(structures)==3:\n",
    "        for n in range(len(bend_deviations_old)):\n",
    "            bend_deviations_old[n] = np.sum(np.abs(bend_values[0,n] - bend_values[-1,n]))\n",
    "\n",
    "    if log_bends:\n",
    "        print(\"Bends:\")\n",
    "        for n in range(len(bend_deviations)):\n",
    "            if not bend_deviations[n] < 2*deg:\n",
    "                print(bends[n], np.rad2deg(bend_deviations[n]))\n",
    "\n",
    "    dihedral_deviations = np.zeros(dih_values.shape[1])\n",
    "    for n in range(len(dihedral_deviations)):\n",
    "        dihedral_deviations[n] = np.average(np.arccos(np.cos(dih_values[-2,n]-dih_values[-1,n])))\n",
    "        \n",
    "        \n",
    "    dihedral_deviations_old = np.zeros(dih_values.shape[1])\n",
    "    if len(structures)==3:\n",
    "        for n in range(len(dihedral_deviations_old)):\n",
    "            dihedral_deviations_old[n] = np.average(np.arccos(np.cos(dih_values[0,n]-dih_values[-1,n])))\n",
    "\n",
    "    if log_dihedrals:\n",
    "        uniq_dih_axes = []\n",
    "        print(\"Dihedrals:\")\n",
    "        for n in range(len(dihedral_deviations)):\n",
    "            if not dihedral_deviations[n] < 10*deg:\n",
    "                if dihs[n][1:3] not in uniq_dih_axes and dihs[n][2:0:-1] not in uniq_dih_axes:\n",
    "                    uniq_dih_axes.append(dihs[n][1:3])\n",
    "                    print(dihs[n][1:3], np.rad2deg(dihedral_deviations[n]))\n",
    "\n",
    "                \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Plot trajectory of ICs\n",
    "    num_plots = int(log_bonds+log_bends+log_dihedrals)\n",
    "    index = 0\n",
    "    fig,ax = pt.subplots(num_plots,1,figsize=(10,30),sharex=True)\n",
    "    if num_plots==1:\n",
    "        ax = [ax]\n",
    "    \n",
    "    if log_bonds:\n",
    "        for n in range(bond_values.shape[1]):\n",
    "            if bond_deviations[n] > 1e-2:\n",
    "                ax[index].plot(range(len(structures)),bond_values[:,n],marker='o',label=str(bonds[n]))\n",
    "            elif bond_deviations_old[n] > 1e-2:\n",
    "                ax[index].plot(range(len(structures)),bond_values[:,n],marker='o')\n",
    "        ax[index].set_title('Bonds')\n",
    "        ax[index].legend(bbox_to_anchor=(1.1,.5), loc='center left',frameon=False)\n",
    "        index+=1\n",
    "    \n",
    "\n",
    "    if log_bends:\n",
    "        for n in range(bend_values.shape[1]):\n",
    "            if bend_deviations[n] > 2*deg:\n",
    "                ax[index].plot(range(len(structures)),np.rad2deg(bend_values[:,n]),marker='o',label=str(bends[n]))\n",
    "            elif bend_deviations_old[n] > 2*deg:\n",
    "                ax[index].plot(range(len(structures)),np.rad2deg(bend_values[:,n]),linestyle='--',marker='o',alpha=0.5)\n",
    "        ax[index].set_title('Bends')\n",
    "        ax[index].legend(bbox_to_anchor=(1.1,.5), loc='center left',frameon=False)\n",
    "        index+=1\n",
    "\n",
    "    if log_dihedrals:\n",
    "        for n in range(dih_values.shape[1]):\n",
    "            if dihedral_deviations[n] > 10*deg:\n",
    "                ax[index].plot(range(len(structures)),np.rad2deg(dih_values[:,n]),marker='o',label=str(dihs[n]))\n",
    "            elif dihedral_deviations_old[n] > 10*deg:\n",
    "                ax[index].plot(range(len(structures)),np.rad2deg(dih_values[:,n]),linestyle='--',marker='o',alpha=0.5)\n",
    "\n",
    "        ax[index].legend(bbox_to_anchor=(1.1,.5), loc='center left',frameon=False)\n",
    "        ax[index].set_title('Dihedrals')\n",
    "        \n",
    "    ax[index].set_xticks(range(len(structures)))\n",
    "    ax[index].set_xticklabels(structures.keys())\n",
    "    \n",
    "    if save_png:\n",
    "        path = pr.root_path +  pr.project_path.split('/')[0] + '/input_files/' + '/'.join(pr.project_path.split('/')[1:]) + '{}/ICs/'.format(ff.block_name)\n",
    "        pathlib.Path(path).mkdir(parents=True, exist_ok=True) # make directory if it does not exist\n",
    "        pt.savefig(path+'{}.png'.format(name))\n",
    "    \n",
    "    pt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_tr = Project('barriers/triazine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather structures & force fields\n",
    "\n",
    "# ffpars_nodih will be calculated by the write_ffpars_nodih function\n",
    "# ffpars_polysix will be calculated by the write_ffpars_polysix function\n",
    "\n",
    "ffs_triazine = {}\n",
    "\n",
    "for block in glob.glob('./input_files/barriers/triazine/*/'):\n",
    "    block_name = block.split('/')[-2]\n",
    "    print(block_name)\n",
    "    ffpars_fns = [fn for fn in glob.glob(block+'ff_pars/*.txt')]    \n",
    "    fn_ai = block+block_name+'_freq.fchk'\n",
    "    tmp = pr.create_job(pr.job_type.Yaff,'tmp',delete_existing_job=True)\n",
    "    tmp.load_chk(block+block_name+'_freq.chk')\n",
    "    structure = tmp.structure # ai structure\n",
    "    tmp.load_chk(block+block_name+'.chk')\n",
    "    ffs_triazine[block_name] = FFobject(block_name,structure,tmp.ffatypes,tmp.ffatype_ids,tmp.bonds,ffpars_fns,fn_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dihed_list = {}\n",
    "with open('./input_files/barriers/triazine/diheds.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    split = line.split()\n",
    "    dihed_list[split[0]] = tuple(int(i) for i in split[1].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure info and rotation grid\n",
    "# Degeneracy will be replaced by numerical value in the write_ffpars_nodih function\n",
    "sinfos_triazine = {\n",
    "    k.replace('-','_') : Sinfo(pr_tr, ffs_triazine[k], v, range_max=180) for k,v in dihed_list.items() if k in ffs_triazine\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinfos_triazine['Adamantane_Nitrile_Triazine'].range_max=60 # should have symmetry of 60 degrees (30 if mirrored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create groups - each key should be a group here\n",
    "sinfo_triazine_groups = {}\n",
    "groups = [k.replace('-','_') for k in list(ffs_triazine.keys())]\n",
    "\n",
    "for name in groups:\n",
    "    group_info = {}\n",
    "    for sname,sinfo in sinfos_triazine.items():\n",
    "        if sname.startswith(name):\n",
    "            group_info[sname] = sinfo\n",
    "            \n",
    "    if len(group_info)>0:     \n",
    "        sinfo_triazine_groups[name] = group_info\n",
    "\n",
    "for n,(k,v) in enumerate(sinfo_triazine_groups.items()):\n",
    "    print(n,k,list(v.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the rotation is significantly hindered, or the \n",
    "gic_triazine = {\n",
    "        \"Adamantane_Nitrile_Triazine\" : \"dihedral(freeze)=D(9,5,23,26)\", # indices start from 1 instead of 0 for gic\n",
    "        \"T_brick_Nitrile_Triazine\" : \"FreezeAll\\nAng0 = A(21,43,44)\", # indices start from 1 instead of 0 for gic\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check whether only the dihedrals are changing\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    plot_IC_variations(name,sinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then alter the ff objects with the altered ffpars\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    write_ffpars_nodih(name,sinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    if not name in gic_triazine:\n",
    "        print(name)\n",
    "        pr_sub = Project(sinfo.get_sub_project_name(name))\n",
    "        grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "        for n,val in enumerate(grid):\n",
    "            adapted_structure = sinfo.adapt_structure(sinfo.ff.structure,val)\n",
    "            g16_job(pr_sub,adapted_structure,'job_{}'.format(n),run_time=2*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the gic scans\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    if name in gic_triazine:\n",
    "        if name not in ['T_brick_Nitrile_Triazine']:\n",
    "            print(name)\n",
    "            pr_sub = Project(sinfo.get_sub_project_name(name))\n",
    "            grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "            for n,val in enumerate(grid):\n",
    "                adapted_structure = sinfo.adapt_structure(sinfo.ff.structure,val)\n",
    "                g16_gic_job(pr_sub,adapted_structure,'job_{}'.format(n),suffix=gic_triazine[name],run_time=10*60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ext_0 = Project('barriers/ctfs')\n",
    "pr_ext_1 = Project('barriers/ctf-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather structures & force fields\n",
    "\n",
    "# ffpars_nodih will be calculated by the write_ffpars_nodih function\n",
    "# ffpars_polysix will be calculated by the write_ffpars_polysix function\n",
    "\n",
    "ffs_ext = {}\n",
    "\n",
    "for block in glob.glob('./input_files/barriers/Sara/*/'):\n",
    "    block_name = block.split('/')[-2]\n",
    "    if block_name in ['Phenyl_Nitrile_Triazine','F_Nitrile_Triazine','BiPhenyl_Nitrile_Triazine']:\n",
    "        print(block_name)\n",
    "        ffpars_fns = [fn for fn in glob.glob(block+'ff_pars/*.txt') if not 'uff' in fn] \n",
    "        fn_ai = block+block_name+'_freq.fchk'\n",
    "        tmp = pr.create_job(pr.job_type.Yaff,'tmp',delete_existing_job=True)\n",
    "        tmp.load_chk(block+block_name+'_freq.chk')\n",
    "        structure = tmp.structure # ai structure\n",
    "        tmp.load_chk(block+'system_opt.chk')\n",
    "        ffs_ext[block_name] = FFobject(block_name,structure,tmp.ffatypes,tmp.ffatype_ids,tmp.bonds,ffpars_fns,fn_ai)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "for block in glob.glob('./input_files/barriers/ctf-1/*/'):\n",
    "    block_name = block.split('/')[-2]\n",
    "    if block_name in ['Triazine']:\n",
    "        ei = 'mbis_gaussian'\n",
    "        vdw = 'mm3'\n",
    "\n",
    "        name = block_name+'_{}_{}'.format(ei,vdw)\n",
    "        print(name)\n",
    "        ffpars_fns = [\n",
    "                        block+'cov/pars_cluster_cov_{}_{}.txt'.format(ei,vdw),\n",
    "                        block+'ei/pars_cluster_{}.txt'.format(ei),\n",
    "                        block+'vdw/pars_{}.txt'.format(vdw)\n",
    "                     ]\n",
    "\n",
    "        fn_ai = block+block_name+'_freq.fchk'\n",
    "        tmp = pr.create_job(pr.job_type.Yaff,'tmp',delete_existing_job=True)\n",
    "        tmp.load_chk(block+block_name+'_freq.chk')\n",
    "        structure = tmp.structure # ai structure\n",
    "        tmp.load_chk(block+block_name+'_ai.chk')\n",
    "        ffs_ext[name] = FFobject(block_name,structure,tmp.ffatypes,tmp.ffatype_ids,tmp.bonds,ffpars_fns,fn_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure info and rotation grid\n",
    "# Degeneracy will be replaced by numerical value in the write_ffpars_nodih function\n",
    "sinfos_ext = {\n",
    "    'BiPhenyl_Nitrile_Triazine_triazine' : Sinfo(pr_ext_0,ffs_ext['BiPhenyl_Nitrile_Triazine'],(21,20,0,5)), # phenyl wrt triazine rot barrier\n",
    "    'F_Nitrile_Triazine'                 : Sinfo(pr_ext_0,ffs_ext['F_Nitrile_Triazine'],(11,10,4,2)), # phenyl with all F functionality wrt triazine rot barrier\n",
    "    'Phenyl_Nitrile_Triazine'            : Sinfo(pr_ext_0,ffs_ext['Phenyl_Nitrile_Triazine'],(11,10,0,5)), # phenyl wrt triazine barrier    \n",
    "    \n",
    "    'Triazine_mbis_gaussian_mm3'         : Sinfo(pr_ext_1,ffs_ext['Triazine_mbis_gaussian_mm3'],(1,0,6,7)), # triazine rot barrier\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create groups - each key should be a group here\n",
    "sinfo_ext_groups = {}\n",
    "groups = [k.replace('-','_') for k in list(ffs_ext.keys())]\n",
    "\n",
    "for name in groups:\n",
    "    group_info = {}\n",
    "    for sname,sinfo in sinfos_ext.items():\n",
    "        if sname.startswith(name):\n",
    "            group_info[sname] = sinfo\n",
    "            \n",
    "    if len(group_info)>0:     \n",
    "        sinfo_ext_groups[name] = group_info\n",
    "\n",
    "for n,(k,v) in enumerate(sinfo_ext_groups.items()):\n",
    "    print(n,k,list(v.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check whether only the dihedrals are changing\n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    plot_IC_variations(name,sinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then alter the ff objects with the altered ffpars\n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    write_ffpars_nodih(name,sinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans\n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    print(name)\n",
    "    pr_sub = Project(sinfo.get_sub_project_name(name))\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    for n,val in enumerate(grid):\n",
    "        adapted_structure = sinfo.adapt_structure(sinfo.ff.structure,val)\n",
    "        g16_job(pr_sub,adapted_structure,'job_{}'.format(n),run_time=2*60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI barrier data parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather AI data for each project with pyiron table\n",
    "\n",
    "def cluster_pos(positions, rvecs, indices):\n",
    "    import itertools\n",
    "    pos = copy.copy(positions)\n",
    "    a,b,c = rvecs[0], rvecs[1], rvecs[2]\n",
    "    for n in indices[1:]:\n",
    "        images = pos[n] + np.array([sum(n * vec for n, vec in zip(ns, [a,b,c])) for ns in itertools.product([-1,0,1],repeat=3)]) # 3 dimensions\n",
    "        distances = np.linalg.norm(images-pos[indices[0]], axis=-1)\n",
    "        pos[n] = images[np.argmin(distances)]\n",
    "    return pos\n",
    "\n",
    "def normal(v1,v2):\n",
    "    n = np.cross(v1,v2, axis=-1)\n",
    "    return (n.T/np.linalg.norm(n,axis=-1)).T\n",
    "\n",
    "def get_dihedral(job,indices,scan=False,cluster=True):\n",
    "    pos = job['output/generic/positions']\n",
    "    \n",
    "    # If an optimization happened only consider final frame, if this was a scan job, get all data\n",
    "    if not scan and pos.shape[0]>1:\n",
    "        pos = pos[-1,:,:].reshape(1,-1,3)\n",
    "\n",
    "    # pbc might have moved atoms\n",
    "    if cluster and job.get('output/generic/cells') is not None:\n",
    "        cells = job.get('output/generic/cells')\n",
    "        if len(cells.shape)==3:\n",
    "            cells = cells[-1,:,:]\n",
    "        pos = cluster_pos(pos, cells, indices)\n",
    "\n",
    "    i1,i2,i3,i4 = indices\n",
    "    n1 = normal(pos[:,i2,:] - pos[:,i1,:], pos[:,i3,:] - pos[:,i2,:])\n",
    "    n2 = normal(pos[:,i3,:] - pos[:,i2,:], pos[:,i4,:] - pos[:,i3,:])\n",
    "    try:\n",
    "        phi = np.arccos(np.einsum('ij,ij->i',n1,n2))\n",
    "    except FloatingPointError:\n",
    "        phi = np.arccos(np.clip(np.einsum('ij,ij->i',n1,n2),-1.,1.))\n",
    "    signs = np.sign(np.einsum('ij,ij->i',n1,pos[:,i4,:] - pos[:,i3,:]))\n",
    "    phi *= signs\n",
    "    phi[np.isclose(phi,-np.pi,atol=1e-4)] = -phi[np.isclose(phi,-np.pi,atol=1e-4)]\n",
    "    \n",
    "    return phi\n",
    "\n",
    "def get_e(job):\n",
    "    energy = job['output/generic/energy_tot']*electronvolt\n",
    "    if isinstance(energy,np.ndarray):\n",
    "        return energy[-1]\n",
    "    else:\n",
    "        return energy\n",
    "\n",
    "def get_table(pr,name,grid,sinfo):\n",
    "    # Create table\n",
    "    name = name.translate({ord(c): None for c in '!@#$(),/-'})\n",
    "    table = pr.create_table('table_'+name, delete_existing_job=True)\n",
    "    \n",
    "    def db_filter(job_table):\n",
    "        return (job_table.status == \"finished\") & (job_table.hamilton != 'TableJob') & (job_table.job.str.contains('job_', regex=False))\n",
    "    \n",
    "    #def get_angle(job,indices=sinfo.indices):\n",
    "    #    return grid[int(job.job_name.split('_')[1])] # in degrees\n",
    "    \n",
    "    table.db_filter_function = db_filter\n",
    "    #table.convert_to_object = True  \n",
    "    \n",
    "    # Introduce property function\n",
    "    if sinfo.fit_indices is not None:\n",
    "        indices = sinfo.fit_indices\n",
    "        ref_indices = sinfo.indices\n",
    "        table.add[\"reference_angle\"] = lambda job: get_dihedral(job,ref_indices)[-1]/deg\n",
    "    else:\n",
    "        indices = sinfo.indices\n",
    "        \n",
    "    table.add[\"angle\"] = lambda job: get_dihedral(job,indices,cluster=False)[-1]/deg   # gaussian can never have pbcs\n",
    "    table.add[\"E\"] = get_e\n",
    "     \n",
    "    # Run it\n",
    "    table.run()\n",
    "    \n",
    "    # Get the dataframe\n",
    "    return table.get_dataframe()\n",
    "\n",
    "# Plotting function\n",
    "def plot(name,aid):\n",
    "    print(name)\n",
    "    fig,ax = pt.subplots(1,2,sharey=True,figsize=(25,5))\n",
    "    \n",
    "    angles = aid.sort_values(by=['angle']).angle\n",
    "    energy = aid.sort_values(by=['angle']).E/kjmol\n",
    "\n",
    "    ax[0].plot(angles,energy, 'bo--')\n",
    "    ax[0].set_xlabel(u'Dihedral angle (°)')\n",
    "    ax[0].set_ylabel('E (kJ/mol)')\n",
    "    ax[0].set_xlim([min(angles), max(angles)])\n",
    "\n",
    "\n",
    "    xc = np.array(np.cos(np.deg2rad(angles)))\n",
    "    yc = energy\n",
    "\n",
    "    ax[1].plot(xc,yc,'bo--')\n",
    "    ax[1].set_xlabel(u'cos $\\phi$')\n",
    "    #ax[1].set_ylabel('E (kJ/mol)')\n",
    "    ax[1].set_xlim([min(xc), max(xc)])\n",
    "    ax[1].axvline(0,0,100,c='k')\n",
    "    pt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data\n",
    "ai_data_triazine = {}\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    print(sinfo.get_sub_project_name(name))\n",
    "    pr_sub = Project(sinfo.get_sub_project_name(name))\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    ai_data_triazine[name] = get_table(pr_sub,name,grid,sinfo)\n",
    "    \n",
    "    # These structures were not perfectly generated\n",
    "    ai_data_triazine[name].angle = grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "for name,aid in ai_data_triazine.items():\n",
    "    plot(name,aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data\n",
    "ai_data_ext = {}\n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    print(sinfo.get_sub_project_name(name))\n",
    "    \n",
    "    if name in ['Triazine_mbis_gaussian_mm3']:\n",
    "        pr_sub = Project(sinfo.get_sub_project_name('Triazine_hi_mm3'))\n",
    "    else:\n",
    "        pr_sub = Project(sinfo.get_sub_project_name(name))\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    ai_data_ext[name] = get_table(pr_sub,name,grid,sinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "for name,aid in ai_data_ext.items():\n",
    "    plot(name,aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FF barrier data calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    if name not in gic_triazine:\n",
    "        yaff_scan_job(sinfo.pr, 'scan_'+name+'_nodih', sinfo, sinfo.ff.ffpars_nodih)\n",
    "        yaff_scan_job(sinfo.pr, 'scan_'+name+'_wdih', sinfo, sinfo.ff.ffpars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    if name in gic_triazine and name in ['Adamantane_Nitrile_Triazine']:\n",
    "        pr_sub_g16 = Project(sinfo.get_sub_project_name(name))\n",
    "        structures = [pr_sub_g16.load('job_{}'.format(n)).get_structure() for n,_ in enumerate(np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step))]\n",
    "        yaff_scan_structures_job(sinfo.pr, 'scan_'+name+'_nodih', sinfo, sinfo.ff.ffpars_nodih, structures)\n",
    "        yaff_scan_structures_job(sinfo.pr, 'scan_'+name+'_wdih', sinfo, sinfo.ff.ffpars, structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans - no GIC\n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    name = name.translate({ord(c): None for c in '!@#$(),/-'})\n",
    "    yaff_scan_job(sinfo.pr, 'scan_'+name+'_nodih', sinfo, sinfo.ff.ffpars_nodih)\n",
    "    yaff_scan_job(sinfo.pr, 'scan_'+name+'_wdih', sinfo, sinfo.ff.ffpars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FF barrier data parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T11:19:23.575561Z",
     "start_time": "2023-01-18T11:19:23.122702Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataclass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c067472a3a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFF_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtable_nodih\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtable_wdih\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtable_polysix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataclass' is not defined"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class FF_data:\n",
    "    table_nodih: object\n",
    "    table_wdih: object\n",
    "    table_polysix: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_tables_ff(name,sinfo,grid):\n",
    "    name = name.translate({ord(c): None for c in '!@#$(),/-'})\n",
    "    nodih = sinfo.pr.load('scan_'+name+'_nodih')\n",
    "    wdih = sinfo.pr.load('scan_'+name+'_wdih')\n",
    "    \n",
    "    if nodih is not None:\n",
    "        epot_contrib_names = [contrib_name.decode(\"utf-8\") for contrib_name in nodih['output/generic/epot_contrib_names']]\n",
    "    else:\n",
    "        epot_contrib_names = [contrib_name.decode(\"utf-8\") for contrib_name in wdih['output/generic/epot_contrib_names']]\n",
    "    \n",
    "    if sinfo.fit_indices is not None:\n",
    "        angles = get_dihedral(nodih,sinfo.fit_indices,scan=True,cluster=False)/deg\n",
    "    else:\n",
    "        angles = get_dihedral(nodih,sinfo.indices,scan=True,cluster=False)/deg\n",
    "        \n",
    "    df_nodih = pd.DataFrame(np.array([angles,*nodih['output/generic/epot_contribs'].T*electronvolt,nodih['output/generic/energy_pot']*electronvolt]).T,\n",
    "                   columns=['angle', *epot_contrib_names, 'e_tot'])\n",
    "    df_wdih = pd.DataFrame(np.array([angles,*wdih['output/generic/epot_contribs'].T*electronvolt,wdih['output/generic/energy_pot']*electronvolt]).T,\n",
    "                   columns=['angle', *epot_contrib_names, 'e_tot'])\n",
    "\n",
    "    # Get the dataframe\n",
    "    return df_nodih, df_wdih\n",
    "\n",
    "def get_table_polysix(name,sinfo,grid):\n",
    "    name = name.translate({ord(c): None for c in '!@#$(),/-'})\n",
    "    polysix = sinfo.pr.load('scan_'+name+'_polysix')\n",
    "    if sinfo.fit_indices is not None:\n",
    "        angles = get_dihedral(polysix,sinfo.fit_indices,scan=True,cluster=False)/deg\n",
    "    else:\n",
    "        angles = get_dihedral(polysix,sinfo.indices,scan=True,cluster=False)/deg\n",
    "    return pd.DataFrame(np.array([angles,polysix['output/generic/energy_pot']*electronvolt]).T,\n",
    "                   columns=['angle', 'e_tot'])\n",
    "\n",
    "def centre(arr):\n",
    "    return (arr-np.nanmin(arr))\n",
    "\n",
    "# Plotting and fitting function\n",
    "def fit_and_plot_ff(name,sinfo,aid,ffd,save_png=False):\n",
    "    from scipy import optimize\n",
    "\n",
    "    print(name)\n",
    "    odd = True # will select correct poly function\n",
    "    \n",
    "    vdw_names = ['pair_mm3','pair_lj','pair_mm3cap']\n",
    "    if len(ffd.table_nodih)>0:\n",
    "        vdw_name = [name for name in vdw_names if name in list(ffd.table_nodih.columns)]\n",
    "    else:\n",
    "        vdw_name = [name for name in vdw_names if name in list(ffd.table_wdih.columns)]\n",
    "    assert len(vdw_name)==1\n",
    "    vdw_name = vdw_name[0]\n",
    "    \n",
    "    \n",
    "    # FF data\n",
    "    if len(ffd.table_nodih)>0:\n",
    "        angles       = ffd.table_nodih.sort_values(by=['angle']).angle\n",
    "        FF_val_nodih = ffd.table_nodih.sort_values(by=['angle']).valence/kjmol\n",
    "        FF_ei_nodih  = ffd.table_nodih.sort_values(by=['angle']).pair_ei/kjmol\n",
    "        FF_vdw_nodih = ffd.table_nodih.sort_values(by=['angle'])[vdw_name]/kjmol\n",
    "        FF_tot_nodih = ffd.table_nodih.sort_values(by=['angle']).e_tot/kjmol\n",
    "        \n",
    "    else:\n",
    "        angles       = ffd.table_wdih.sort_values(by=['angle']).angle\n",
    "    \n",
    "    FF_val_wdih = ffd.table_wdih.sort_values(by=['angle']).valence/kjmol\n",
    "    FF_ei_wdih  = ffd.table_wdih.sort_values(by=['angle']).pair_ei/kjmol\n",
    "    FF_vdw_wdih = ffd.table_wdih.sort_values(by=['angle'])[vdw_name]/kjmol\n",
    "    FF_tot_wdih = ffd.table_wdih.sort_values(by=['angle']).e_tot/kjmol\n",
    "    \n",
    "    # AI data\n",
    "    if aid is not None:\n",
    "        ai_angles   = aid.sort_values(by=['angle']).angle\n",
    "        ai_energy   = aid.sort_values(by=['angle']).E/kjmol\n",
    "        try:\n",
    "            assert np.all(np.isclose(np.asarray(ai_angles),np.asarray(angles),atol=1e-3))\n",
    "        except AssertionError:\n",
    "            print(np.asarray(ai_angles),np.asarray(angles))\n",
    "            print(np.isclose(np.asarray(ai_angles),np.asarray(angles),atol=1e-4))\n",
    "            raise AssertionError\n",
    "    \n",
    "    \n",
    "    # If angle range is limited to 90 degrees mirror the behaviour to 180\n",
    "    def mirror(array, angle=False):\n",
    "        if angle:\n",
    "            return np.hstack((array, 180-array[:-1][::-1]))\n",
    "        else:\n",
    "            return np.hstack((array, array[:-1][::-1]))\n",
    "    \n",
    "    \n",
    "    def mirror60(array, angle=False):\n",
    "        if angle:\n",
    "            return np.hstack((array, 120-array[:-1][::-1], 120+array[1:]))\n",
    "        else:\n",
    "            return np.hstack((array, array[:-1][::-1], array[1:]))\n",
    "        \n",
    "        \n",
    "    if np.isclose(np.max(angles),90,atol=1e-5):\n",
    "        print('Mirroring - 90')\n",
    "        odd = False\n",
    "        angles       = mirror(angles,angle=True)\n",
    "        if len(ffd.table_nodih)>0:\n",
    "            FF_val_nodih = mirror(FF_val_nodih)\n",
    "            FF_ei_nodih  = mirror(FF_ei_nodih)\n",
    "            FF_vdw_nodih = mirror(FF_vdw_nodih)\n",
    "            FF_tot_nodih = mirror(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = mirror(FF_val_wdih)\n",
    "        FF_ei_wdih  = mirror(FF_ei_wdih)\n",
    "        FF_vdw_wdih = mirror(FF_vdw_wdih)\n",
    "        FF_tot_wdih = mirror(FF_tot_wdih)\n",
    "        \n",
    "        if aid is not None:\n",
    "            ai_energy   = mirror(ai_energy)\n",
    "    elif np.isclose(np.max(angles),60,atol=1e-5):\n",
    "        print('Mirroring - 60')\n",
    "        angles       = mirror60(angles,angle=True)\n",
    "        if len(ffd.table_nodih)>0:\n",
    "            FF_val_nodih = mirror60(FF_val_nodih)\n",
    "            FF_ei_nodih  = mirror60(FF_ei_nodih)\n",
    "            FF_vdw_nodih = mirror60(FF_vdw_nodih)\n",
    "            FF_tot_nodih = mirror60(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = mirror60(FF_val_wdih)\n",
    "        FF_ei_wdih  = mirror60(FF_ei_wdih)\n",
    "        FF_vdw_wdih = mirror60(FF_vdw_wdih)\n",
    "        FF_tot_wdih = mirror60(FF_tot_wdih)\n",
    "        \n",
    "        if aid is not None:\n",
    "            ai_energy   = mirror60(ai_energy)\n",
    "    else:\n",
    "        angles      = np.asarray(angles)\n",
    "        \n",
    "        if len(ffd.table_nodih)>0:\n",
    "            FF_val_nodih = np.asarray(FF_val_nodih)\n",
    "            FF_ei_nodih  = np.asarray(FF_ei_nodih)\n",
    "            FF_vdw_nodih = np.asarray(FF_vdw_nodih)\n",
    "            FF_tot_nodih = np.asarray(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = np.asarray(FF_val_wdih)\n",
    "        FF_ei_wdih  = np.asarray(FF_ei_wdih)\n",
    "        FF_vdw_wdih = np.asarray(FF_vdw_wdih)\n",
    "        FF_tot_wdih = np.asarray(FF_tot_wdih)\n",
    "        \n",
    "        if aid is not None:\n",
    "            ai_energy   = np.asarray(ai_energy)\n",
    "        \n",
    "    def get_poly(odd):\n",
    "        # Fit functions\n",
    "        def poly(x,b,d,f,g):\n",
    "            return g + b*x**2 + d*x**4 + f*x**6\n",
    "\n",
    "        def poly_odd(x,a,b,c,d,e,f,g):\n",
    "            return g + a*x + b*x**2 + c*x**3 + d*x**4 + e*x**5 + f*x**6\n",
    "        \n",
    "        if odd:\n",
    "            return poly_odd\n",
    "        else:\n",
    "            return poly\n",
    "        \n",
    "    fpoly = get_poly(odd)\n",
    "    \n",
    "    if aid is not None:\n",
    "        # Calculate difference and fit a polysix term to the difference, focussing on the minimum\n",
    "        diff = centre(ai_energy - FF_tot_nodih)\n",
    "\n",
    "        cosr = np.cos(np.deg2rad(angles)) # range as cos(x)\n",
    "        fitr = cosr[~np.isnan(diff)]\n",
    "        fitf = diff[~np.isnan(diff)]\n",
    "\n",
    "        sigma=np.ones(len(fitf))\n",
    "        #sigma[np.argmin(fitf)] = 1e-4 # force minimum position\n",
    "        #sigma[centre(ai_energy)<20*kjmol] = 1e-4\n",
    "        p,pcov = optimize.curve_fit(fpoly, fitr, fitf, sigma=sigma)\n",
    "        print(p)\n",
    "\n",
    "\n",
    "        # Plot FF and AI data and compare with fit\n",
    "        fig,ax = pt.subplots(2,2,sharex=True,sharey=True,figsize=(25,10))\n",
    "        ax[0,0].plot(angles,centre(FF_val_nodih), label='valence')\n",
    "        ax[0,0].plot(angles,centre(FF_ei_nodih), label='ei')\n",
    "        ax[0,0].plot(angles,centre(FF_vdw_nodih), label='vdw')\n",
    "        ax[0,0].plot(angles,centre(FF_tot_nodih), ls='--', label='tot')\n",
    "        ax[0,0].plot(angles,centre(ai_energy), label='AI')\n",
    "        ax[0,0].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "        ax[0,0].set_ylabel('E (kJ/mol)')\n",
    "        ax[0,0].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "        ax[0,0].set_title('Energy barrier wo dihedral term')\n",
    "\n",
    "        ax[0,1].plot(angles,centre(FF_val_wdih), label='valence')\n",
    "        ax[0,1].plot(angles,centre(FF_ei_wdih), label='ei')\n",
    "        ax[0,1].plot(angles,centre(FF_vdw_wdih), label='vdw')\n",
    "        ax[0,1].plot(angles,centre(FF_tot_wdih), ls='--', label='tot')\n",
    "        ax[0,1].plot(angles,centre(ai_energy), label='AI')\n",
    "        ax[0,1].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "        ax[0,1].set_ylabel('E (kJ/mol)')\n",
    "        ax[0,1].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "        ax[0,1].set_title('Energy barrier w dihedral term')\n",
    "\n",
    "        ax[1,0].plot(angles,diff, c='r', label='diff')\n",
    "        ax[1,0].plot(angles,fpoly(cosr,*p), 'k--', label='fit')\n",
    "        ax[1,0].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "        ax[1,0].set_ylabel('E (kJ/mol)')\n",
    "        ax[1,0].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "        ax[1,0].set_title('Fit (wrt diff)')\n",
    "\n",
    "        ax[1,1].plot(angles,centre(ai_energy), label='AI', c='r')\n",
    "        ax[1,1].plot(angles,centre(fpoly(cosr,*p) + FF_tot_nodih), 'k--',label='fit')\n",
    "        ax[1,1].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "        ax[1,1].set_ylabel('E (kJ/mol)')\n",
    "        ax[1,1].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "        ax[1,1].set_title('Fit (wrt AI barrier)')\n",
    "        \n",
    "        '''\n",
    "        ax[2,0].plot(cosr,diff, c='r', label='diff')\n",
    "        ax[2,0].plot(cosr,fpoly(cosr,*p), 'k--', label='fit')\n",
    "        ax[2,0].set_xlabel(r'$\\cos \\psi$')\n",
    "        ax[2,0].set_ylabel('E (kJ/mol)')\n",
    "        ax[2,0].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "        ax[2,0].set_title('Fit (wrt diff)')\n",
    "\n",
    "        ax[2,1].plot(cosr,centre(ai_energy), label='AI', c='r')\n",
    "        ax[2,1].plot(cosr,centre(fpoly(cosr,*p) + FF_tot_nodih), 'k--',label='fit')\n",
    "        ax[2,1].set_xlabel(r'$\\cos \\psi$ ($^\\circ$)')\n",
    "        ax[2,1].set_ylabel('E (kJ/mol)')\n",
    "        ax[2,1].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "        ax[2,1].set_title('Fit (wrt AI barrier)')\n",
    "        '''\n",
    "        \n",
    "    else:\n",
    "        # Plot FF and AI data and compare with fit\n",
    "        if len(ffd.table_nodih)>0:\n",
    "            fig,ax = pt.subplots(1,2,sharex=True,sharey=True,figsize=(30,10))\n",
    "            ax[0].plot(angles,centre(FF_val_nodih), label='valence')\n",
    "            ax[0].plot(angles,centre(FF_ei_nodih), label='ei')\n",
    "            ax[0].plot(angles,centre(FF_vdw_nodih), label='vdw')\n",
    "            ax[0].plot(angles,centre(FF_tot_nodih), ls='--', label='tot')\n",
    "            ax[0].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "            ax[0].set_ylabel('E (kJ/mol)')\n",
    "            ax[0].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "            ax[0].set_title('Energy barrier wo dihedral term')\n",
    "\n",
    "            ax[1].plot(angles,centre(FF_val_wdih), label='valence')\n",
    "            ax[1].plot(angles,centre(FF_ei_wdih), label='ei')\n",
    "            ax[1].plot(angles,centre(FF_vdw_wdih), label='vdw')\n",
    "            ax[1].plot(angles,centre(FF_tot_wdih), ls='--', label='tot')\n",
    "            ax[1].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "            ax[1].set_ylabel('E (kJ/mol)')\n",
    "            ax[1].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "            ax[1].set_title('Energy barrier w dihedral term')\n",
    "        else:\n",
    "            fig,ax = pt.subplots(1,1,sharex=True,sharey=True,figsize=(30,10))\n",
    "            ax.plot(angles,centre(FF_val_wdih), label='valence')\n",
    "            ax.plot(angles,centre(FF_ei_wdih), label='ei')\n",
    "            ax.plot(angles,centre(FF_vdw_wdih), label='vdw')\n",
    "            ax.plot(angles,centre(FF_tot_wdih), ls='--', label='tot')\n",
    "            ax.set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "            ax.set_ylabel('E (kJ/mol)')\n",
    "            ax.legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "            ax.set_title('Energy barrier w dihedral term')\n",
    "\n",
    "    \n",
    "    if save_png:\n",
    "        path = sinfo.pr.root_path +  sinfo.pr.project_path.split('/')[0] + '/input_files/' + '/'.join(sinfo.pr.project_path.split('/')[1:]) + sinfo.ff.block_name + '/fits/'\n",
    "        pathlib.Path(path).mkdir(parents=True, exist_ok=True) # make directory if it does not exist\n",
    "        pt.savefig(path+'{}.pdf'.format(name),bbox_inches='tight')\n",
    "    \n",
    "    pt.show()\n",
    "    \n",
    "    if aid is not None:\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data\n",
    "ff_triazine_datas = {}\n",
    "\n",
    "# table_polysix will be calculated in 6: Testing polysix terms \n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    ff_triazine_datas[name] = FF_data(*get_tables_ff(name,sinfo,grid),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting and Plotting\n",
    "ps_triazine = {}\n",
    "for name,ffd in ff_triazine_datas.items():\n",
    "    ps_triazine[name] = fit_and_plot_ff(name,sinfos_triazine[name],ai_data_triazine[name],ffd,save_png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data\n",
    "ff_ext_datas = {}\n",
    "\n",
    "# table_polysix will be calculated in 6: Testing polysix terms \n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    print(name)\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    ff_ext_datas[name] = FF_data(*get_tables_ff(name,sinfo,grid),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting and Plotting\n",
    "ps_ext = {}\n",
    "for name,ffd in ff_ext_datas.items():\n",
    "    ps_ext[name] = fit_and_plot_ff(name,sinfos_ext[name],ai_data_ext[name],ffd,save_png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating polysix parameterfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def write_ffpars_polysix(sinfo,fit_params,name=None,subname=None,strict_indices=False,ref_val=0,override_degeneracy=None):    \n",
    "    # Make yaff system and adapt it to angle 0\n",
    "    adapted_structure = sinfo.adapt_structure(sinfo.ff.structure,ref_val)\n",
    "    yaff_system = System(sinfo.ff.structure.numbers, adapted_structure.positions, ffatypes=sinfo.ff.ffatypes, ffatype_ids=sinfo.ff.ffatype_ids, bonds=sinfo.ff.bonds)\n",
    "    \n",
    "    # Log all dihedrals\n",
    "    dihs = []\n",
    "    dihs_ids = []\n",
    "    dihs_cos = []\n",
    "    for dih in yaff_system.iter_dihedrals():\n",
    "        dihs.append(dih)\n",
    "        dihs_ids.append([yaff_system.ffatypes[yaff_system.ffatype_ids[i]] for i in dih])\n",
    "        dihs_cos.append(DihedCos(*dih))\n",
    "\n",
    "    # Filter out the appropriate ones\n",
    "    if sinfo.fit_indices is not None:\n",
    "        dihedral_idx = sinfo.fit_indices\n",
    "    else:\n",
    "        dihedral_idx = sinfo.indices\n",
    "    cv_dih = []\n",
    "    cv_dihcos = []\n",
    "    for n,dih in enumerate(dihs):\n",
    "        if (dih[1]==dihedral_idx[1] and dih[2]==dihedral_idx[2]) or (dih[1]==dihedral_idx[2] and dih[2]==dihedral_idx[1]):\n",
    "            if not strict_indices or (strict_indices and (dih == dihedral_idx or dih[::-1] == dihedral_idx)):\n",
    "                if dihs_ids[n] not in cv_dih and dihs_ids[n][::-1] not in cv_dih:\n",
    "                    cv_dih.append(dihs_ids[n])\n",
    "                    cv_dihcos.append(dihs_cos[n])\n",
    "    \n",
    "    # Evaluate these dihedrals\n",
    "    ICl = InternalCoordinateList(DeltaList(yaff_system))\n",
    "    for dih in cv_dihcos:\n",
    "        ICl.add_ic(dih)\n",
    "    ICl.dlist.forward()\n",
    "    ICl.forward()\n",
    "    \n",
    "\n",
    "    values = [int(np.round(c.get_last_computed_value())) for c in cv_dihcos]\n",
    "\n",
    "    powers = [[c**m for m in [1,2,3,4,5,6]] for c in values] # to get the sign right of odd and even powers\n",
    "    w = max([len(n) for dih in cv_dih for n in dih]) # to get nice alligned parameter files\n",
    "    \n",
    "    # Evaluate fit params to 6\n",
    "    fit_params = fit_params[:-1] # do not account for constant term\n",
    "    if not len(fit_params)==6:\n",
    "        fit_params=[0,fit_params[0],0,fit_params[1],0,fit_params[2]]\n",
    "        \n",
    "    ffpars_polysix = ''\n",
    "    ffpars_polysix += '''# TORSCPOLYSIX\n",
    "#---------\n",
    "TORSCPOLYSIX:UNIT  C1 kjmol\n",
    "TORSCPOLYSIX:UNIT  C2 kjmol\n",
    "TORSCPOLYSIX:UNIT  C3 kjmol\n",
    "TORSCPOLYSIX:UNIT  C4 kjmol\n",
    "TORSCPOLYSIX:UNIT  C5 kjmol\n",
    "TORSCPOLYSIX:UNIT  C6 kjmol\n",
    "\n",
    "'''\n",
    "    for n,dih in enumerate(cv_dih):\n",
    "        if override_degeneracy is not None:\n",
    "            tmp = np.array(fit_params)/override_degeneracy\n",
    "        else:\n",
    "            tmp = np.array(fit_params)/sinfo.degeneracy\n",
    "        power = powers[n]\n",
    "        v = [power[m]*tmp[m] for m in range(len(power))]\n",
    "        ffpars_polysix += 'TORSCPOLYSIX:PARS  '\n",
    "        ffpars_polysix += \"{:>{w}}  {:>{w}}  {:>{w}}  {:>{w}}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}\\n\".format(dih[0],dih[1],dih[2],dih[3],v[0],v[1],v[2],v[3],v[4],v[5],w=w)\n",
    "    \n",
    "    \n",
    "    \n",
    "    path = sinfo.pr.root_path +  sinfo.pr.project_path.split('/')[0] + '/input_files/' + '/'.join(sinfo.pr.project_path.split('/')[1:]) + sinfo.ff.block_name + '/polysix/' \n",
    "    path = path + '{}/'.format(name) if name is not None else path\n",
    "    pathlib.Path(path).mkdir(parents=True, exist_ok=True) # make directory if it does not exist\n",
    "    \n",
    "    polysix_path = path+'pars_polysix.txt' if subname is None else path+'pars_polysix_{}.txt'.format(subname)\n",
    "    \n",
    "    with open(polysix_path, 'w') as f:\n",
    "        f.write(ffpars_polysix)\n",
    "    \n",
    "    # Adapt polysix parameters in sinfo\n",
    "    sinfo.ff.ffpars_polysix = ffpars_polysix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in sinfo_triazine_groups.items():\n",
    "    # Group polysix parameter files per group\n",
    "    print('{}: {}'.format(key,','.join(list(val.keys()))))\n",
    "    names = [k for k in val.keys()]\n",
    "    sinfos = [val[k] for k in val.keys()]\n",
    "    for n,sinfo in enumerate(sinfos):\n",
    "        write_ffpars_polysix(sinfo,ps_triazine[names[n]],name='_'.join(key.split('_')[1:]),subname=None) # we don't need subname here, only 1 polysix parameter file per key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in sinfo_ext_groups.items():\n",
    "    # Group polysix parameter files per group\n",
    "    print('{}: {}'.format(key,','.join(list(val.keys()))))\n",
    "    names = [k for k in val.keys()]\n",
    "    sinfos = [val[k] for k in val.keys()]\n",
    "    for n,sinfo in enumerate(sinfos):\n",
    "        write_ffpars_polysix(sinfo,ps_ext[names[n]], name=None, subname=names[n].split('-')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing polysix terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and fitting function\n",
    "def plot_ff_polysix(name,aid,ffd):\n",
    "    print(name)\n",
    "    \n",
    "    vdw_names = ['pair_mm3','pair_lj','pair_mm3cap']\n",
    "    vdw_name = [name for name in vdw_names if name in list(ffd.table_nodih.columns)]\n",
    "    assert len(vdw_name)==1\n",
    "    vdw_name = vdw_name[0]\n",
    "    \n",
    "    # FF data\n",
    "    angles       = ffd.table_nodih.sort_values(by=['angle']).angle\n",
    "    FF_val_nodih = ffd.table_nodih.sort_values(by=['angle']).valence/kjmol\n",
    "    FF_ei_nodih  = ffd.table_nodih.sort_values(by=['angle']).pair_ei/kjmol\n",
    "    FF_vdw_nodih = ffd.table_nodih.sort_values(by=['angle'])[vdw_name]/kjmol\n",
    "    FF_tot_nodih = ffd.table_nodih.sort_values(by=['angle']).e_tot/kjmol\n",
    "    \n",
    "    FF_val_wdih = ffd.table_wdih.sort_values(by=['angle']).valence/kjmol\n",
    "    FF_ei_wdih  = ffd.table_wdih.sort_values(by=['angle']).pair_ei/kjmol\n",
    "    FF_vdw_wdih = ffd.table_wdih.sort_values(by=['angle'])[vdw_name]/kjmol\n",
    "    FF_tot_wdih = ffd.table_wdih.sort_values(by=['angle']).e_tot/kjmol\n",
    "    \n",
    "    poly_angles  = ffd.table_polysix.sort_values(by=['angle']).angle\n",
    "    FF_poly      = ffd.table_polysix.sort_values(by=['angle']).e_tot/kjmol\n",
    "    \n",
    "    # AI data\n",
    "    ai_angles   = aid.sort_values(by=['angle']).angle\n",
    "    ai_energy   = aid.sort_values(by=['angle']).E/kjmol\n",
    "    \n",
    "    try:\n",
    "        assert np.all(np.isclose(np.asarray(ai_angles),np.asarray(angles)))\n",
    "        assert np.all(np.isclose(np.asarray(poly_angles),np.asarray(angles), atol=1e-4))\n",
    "    except AssertionError:\n",
    "        print(np.asarray(ai_angles)-np.asarray(angles))\n",
    "        print(np.asarray(poly_angles)-np.asarray(angles))\n",
    "        raise AssertionError\n",
    "\n",
    "    \n",
    "    # If angle range is limited to 90 degrees mirror the behaviour to 180\n",
    "    def mirror(array, angle=False):\n",
    "        if angle:\n",
    "            return np.hstack((array, 180-array[:-1][::-1]))\n",
    "        else:\n",
    "            return np.hstack((array, array[:-1][::-1]))\n",
    "        \n",
    "    def mirror60(array, angle=False):\n",
    "        if angle:\n",
    "            return np.hstack((array, 120-array[:-1][::-1], 120+array[1:]))\n",
    "        else:\n",
    "            return np.hstack((array, array[:-1][::-1], array[1:]))\n",
    "        \n",
    "    if np.max(angles)==90:\n",
    "        print('Mirroring')\n",
    "        angles       = mirror(angles,angle=True)\n",
    "        FF_val_nodih = mirror(FF_val_nodih)\n",
    "        FF_ei_nodih  = mirror(FF_ei_nodih)\n",
    "        FF_vdw_nodih = mirror(FF_vdw_nodih)\n",
    "        FF_tot_nodih = mirror(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = mirror(FF_val_wdih)\n",
    "        FF_ei_wdih  = mirror(FF_ei_wdih)\n",
    "        FF_vdw_wdih = mirror(FF_vdw_wdih)\n",
    "        FF_tot_wdih = mirror(FF_tot_wdih)\n",
    "        \n",
    "        FF_poly   = mirror(FF_poly)\n",
    "        ai_energy = mirror(ai_energy)\n",
    "        \n",
    "    elif np.max(angles)==60:\n",
    "        print('Mirroring')\n",
    "        angles       = mirror60(angles,angle=True)\n",
    "        FF_val_nodih = mirror60(FF_val_nodih)\n",
    "        FF_ei_nodih  = mirror60(FF_ei_nodih)\n",
    "        FF_vdw_nodih = mirror60(FF_vdw_nodih)\n",
    "        FF_tot_nodih = mirror60(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = mirror60(FF_val_wdih)\n",
    "        FF_ei_wdih  = mirror60(FF_ei_wdih)\n",
    "        FF_vdw_wdih = mirror60(FF_vdw_wdih)\n",
    "        FF_tot_wdih = mirror60(FF_tot_wdih)\n",
    "        \n",
    "        FF_poly   = mirror60(FF_poly)\n",
    "        ai_energy = mirror60(ai_energy)\n",
    "    else:\n",
    "        angles       = np.asarray(angles)\n",
    "        FF_val_nodih = np.asarray(FF_val_nodih)\n",
    "        FF_ei_nodih  = np.asarray(FF_ei_nodih)\n",
    "        FF_vdw_nodih = np.asarray(FF_vdw_nodih)\n",
    "        FF_tot_nodih = np.asarray(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = np.asarray(FF_val_wdih)\n",
    "        FF_ei_wdih  = np.asarray(FF_ei_wdih)\n",
    "        FF_vdw_wdih = np.asarray(FF_vdw_wdih)\n",
    "        FF_tot_wdih = np.asarray(FF_tot_wdih)\n",
    "        \n",
    "        FF_poly   = np.asarray(FF_poly)\n",
    "        ai_energy = np.asarray(ai_energy)\n",
    "        \n",
    "    \n",
    "    # Plot FF and AI data and compare with fit\n",
    "    fig,ax = pt.subplots(1,2,sharex=True,sharey=True,figsize=(25,10))\n",
    "    ax[0].plot(angles,centre(FF_tot_nodih+FF_poly), label='tot_new_ff')\n",
    "    ax[0].plot(angles,centre(ai_energy), label='AI')\n",
    "    ax[0].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "    ax[0].set_ylabel('E (kJ/mol)')\n",
    "    ax[0].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "    ax[0].set_title('Energy barrier w polysix term')\n",
    "\n",
    "    ax[1].plot(angles,centre(ai_energy-FF_tot_nodih), label='diff')\n",
    "    ax[1].plot(angles,centre(FF_poly), label='polysix')\n",
    "    ax[1].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "    ax[1].set_ylabel('E (kJ/mol)')\n",
    "    ax[1].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "    ax[1].set_title('Energy difference vs polysix')\n",
    "    \n",
    "    pt.show()\n",
    "    \n",
    "def full_plot(pr,name,sinfo,aid,ffd,save_png=False):\n",
    "    print(name)\n",
    "    odd = True # will select correct poly function\n",
    "    \n",
    "    vdw_names = ['pair_mm3','pair_lj','pair_mm3cap']\n",
    "    if len(ffd.table_nodih)>0:\n",
    "        vdw_name = [name for name in vdw_names if name in list(ffd.table_nodih.columns)]\n",
    "    else:\n",
    "        vdw_name = [name for name in vdw_names if name in list(ffd.table_wdih.columns)]\n",
    "    assert len(vdw_name)==1\n",
    "    vdw_name = vdw_name[0]\n",
    "    \n",
    "    \n",
    "    # FF data\n",
    "    if len(ffd.table_nodih)>0:\n",
    "        angles       = ffd.table_nodih.sort_values(by=['angle']).angle\n",
    "        FF_val_nodih = ffd.table_nodih.sort_values(by=['angle']).valence/kjmol\n",
    "        FF_ei_nodih  = ffd.table_nodih.sort_values(by=['angle']).pair_ei/kjmol\n",
    "        FF_vdw_nodih = ffd.table_nodih.sort_values(by=['angle'])[vdw_name]/kjmol\n",
    "        FF_tot_nodih = ffd.table_nodih.sort_values(by=['angle']).e_tot/kjmol\n",
    "        \n",
    "    else:\n",
    "        angles       = ffd.table_wdih.sort_values(by=['angle']).angle\n",
    "    \n",
    "    FF_val_wdih = ffd.table_wdih.sort_values(by=['angle']).valence/kjmol\n",
    "    FF_ei_wdih  = ffd.table_wdih.sort_values(by=['angle']).pair_ei/kjmol\n",
    "    FF_vdw_wdih = ffd.table_wdih.sort_values(by=['angle'])[vdw_name]/kjmol\n",
    "    FF_tot_wdih = ffd.table_wdih.sort_values(by=['angle']).e_tot/kjmol\n",
    "    \n",
    "    poly_angles  = ffd.table_polysix.sort_values(by=['angle']).angle\n",
    "    FF_poly     = ffd.table_polysix.sort_values(by=['angle']).e_tot/kjmol\n",
    "    \n",
    "    # AI data\n",
    "    if aid is not None:\n",
    "        ai_angles   = aid.sort_values(by=['angle']).angle\n",
    "        ai_energy   = aid.sort_values(by=['angle']).E/kjmol\n",
    "    \n",
    "    try:\n",
    "        assert np.all(np.isclose(np.asarray(ai_angles),np.asarray(angles), atol=1e-3))\n",
    "        assert np.all(np.isclose(np.asarray(poly_angles),np.asarray(angles), atol=1e-3))\n",
    "    except AssertionError:\n",
    "        print(np.asarray(ai_angles)-np.asarray(angles))\n",
    "        print(np.asarray(poly_angles)-np.asarray(angles))\n",
    "        raise AssertionError\n",
    "\n",
    "    \n",
    "    # If angle range is limited to 90 degrees mirror the behaviour to 180\n",
    "    def mirror(array, angle=False):\n",
    "        if angle:\n",
    "            return np.hstack((array, 180-array[:-1][::-1]))\n",
    "        else:\n",
    "            return np.hstack((array, array[:-1][::-1]))\n",
    "        \n",
    "    def mirror60(array, angle=False):\n",
    "        if angle:\n",
    "            return np.hstack((array, 120-array[:-1][::-1], 120+array[1:]))\n",
    "        else:\n",
    "            return np.hstack((array, array[:-1][::-1], array[1:]))\n",
    "        \n",
    "    if np.isclose(np.max(angles),90,atol=1e-4):\n",
    "        print('Mirroring')\n",
    "        odd = False\n",
    "        angles       = mirror(angles,angle=True)\n",
    "        if len(ffd.table_nodih)>0:\n",
    "            FF_val_nodih = mirror(FF_val_nodih)\n",
    "            FF_ei_nodih  = mirror(FF_ei_nodih)\n",
    "            FF_vdw_nodih = mirror(FF_vdw_nodih)\n",
    "            FF_tot_nodih = mirror(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = mirror(FF_val_wdih)\n",
    "        FF_ei_wdih  = mirror(FF_ei_wdih)\n",
    "        FF_vdw_wdih = mirror(FF_vdw_wdih)\n",
    "        FF_tot_wdih = mirror(FF_tot_wdih)\n",
    "        FF_poly     = mirror(FF_poly)\n",
    "        \n",
    "        if aid is not None:\n",
    "            ai_energy   = mirror(ai_energy)\n",
    "            \n",
    "    elif np.isclose(np.max(angles),60,atol=1e-3):\n",
    "        print('Mirroring - 60')\n",
    "        angles       = mirror60(angles,angle=True)\n",
    "        if len(ffd.table_nodih)>0:\n",
    "            FF_val_nodih = mirror60(FF_val_nodih)\n",
    "            FF_ei_nodih  = mirror60(FF_ei_nodih)\n",
    "            FF_vdw_nodih = mirror60(FF_vdw_nodih)\n",
    "            FF_tot_nodih = mirror60(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = mirror60(FF_val_wdih)\n",
    "        FF_ei_wdih  = mirror60(FF_ei_wdih)\n",
    "        FF_vdw_wdih = mirror60(FF_vdw_wdih)\n",
    "        FF_tot_wdih = mirror60(FF_tot_wdih)\n",
    "        FF_poly     = mirror60(FF_poly)\n",
    "        \n",
    "        if aid is not None:\n",
    "            ai_energy   = mirror60(ai_energy)           \n",
    "    else:\n",
    "        angles      = np.asarray(angles)\n",
    "        \n",
    "        if len(ffd.table_nodih)>0:\n",
    "            FF_val_nodih = np.asarray(FF_val_nodih)\n",
    "            FF_ei_nodih  = np.asarray(FF_ei_nodih)\n",
    "            FF_vdw_nodih = np.asarray(FF_vdw_nodih)\n",
    "            FF_tot_nodih = np.asarray(FF_tot_nodih)\n",
    "        \n",
    "        FF_val_wdih = np.asarray(FF_val_wdih)\n",
    "        FF_ei_wdih  = np.asarray(FF_ei_wdih)\n",
    "        FF_vdw_wdih = np.asarray(FF_vdw_wdih)\n",
    "        FF_tot_wdih = np.asarray(FF_tot_wdih)\n",
    "        FF_poly     = np.asarray(FF_poly)\n",
    "        \n",
    "        if aid is not None:\n",
    "            ai_energy   = np.asarray(ai_energy)\n",
    "            \n",
    "    # Plot data\n",
    "    fig,ax = pt.subplots(2,sharex=True,sharey=True,figsize=(15,10))\n",
    "    ax[0].plot(angles,centre(FF_val_wdih), label='valence')\n",
    "    ax[0].plot(angles,centre(FF_ei_wdih), label='ei')\n",
    "    ax[0].plot(angles,centre(FF_vdw_wdih), label='vdw')\n",
    "    ax[0].plot(angles,centre(FF_tot_wdih), ls='--', label='tot')\n",
    "    ax[0].plot(angles,centre(ai_energy), label='AI')\n",
    "    ax[0].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "    ax[0].set_ylabel('E (kJ/mol)')\n",
    "    ax[0].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "    ax[0].set_title('Energy barrier - old FF')\n",
    "    ax[1].plot(angles,centre(FF_val_nodih + FF_poly), label='valence')\n",
    "    ax[1].plot(angles,centre(FF_ei_nodih), label='ei')\n",
    "    ax[1].plot(angles,centre(FF_vdw_nodih), label='vdw')\n",
    "    ax[1].plot(angles,centre(FF_tot_nodih + FF_poly), ls='--', label='tot')\n",
    "    ax[1].plot(angles,centre(ai_energy), label='AI')\n",
    "    ax[1].set_xlabel(r'$\\psi$ ($^\\circ$)')\n",
    "    ax[1].set_ylabel('E (kJ/mol)')\n",
    "    ax[1].legend(bbox_to_anchor=(1.0,.5), loc=6)\n",
    "    ax[1].set_title('Energy barrier - new FF')\n",
    "    \n",
    "    if save_png:\n",
    "        path = pr.root_path +  pr.project_path.split('/')[0] + '/input_files/' + '/'.join(pr.project_path.split('/')[1:]) + sinfo.ff.block_name + '/fits/'\n",
    "        pathlib.Path(path).mkdir(parents=True, exist_ok=True) # make directory if it does not exist\n",
    "        pt.savefig(path+'final_{}.pdf'.format(name))\n",
    "    pt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    if not name in gic_triazine:\n",
    "        print(name)\n",
    "        yaff_scan_job(sinfo.pr, 'scan_'+name+'_polysix', sinfo, sinfo.ff.ffpars_polysix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans\n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    if name in gic_triazine:\n",
    "        pr_sub_g16 = Project(sinfo.get_sub_project_name(name))\n",
    "        structures = [pr_sub_g16.load('job_{}'.format(n)).get_structure() for n,_ in enumerate(np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step))]\n",
    "        yaff_scan_structures_job(sinfo.pr, 'scan_'+name+'_polysix', sinfo, sinfo.ff.ffpars_polysix, structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_polysix will be calculated in 6: Testing polysix terms \n",
    "for name,sinfo in sinfos_triazine.items():\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    ff_triazine_datas[name].table_polysix = get_table_polysix(name,sinfo,grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,sinfo in sinfos_triazine.items():\n",
    "    full_plot(sinfo.pr,name,sinfo,ai_data_triazine[name],ff_triazine_datas[name],save_png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the scans - no GIC\n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    print(name)\n",
    "    name = name.translate({ord(c): None for c in '!@#$(),/-'})\n",
    "    yaff_scan_job(sinfo.pr, 'scan_'+name+'_polysix', sinfo, sinfo.ff.ffpars_polysix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_polysix will be calculated in 6: Testing polysix terms \n",
    "for name,sinfo in sinfos_ext.items():\n",
    "    grid = np.arange(sinfo.range_min, sinfo.range_max+sinfo.range_step, sinfo.range_step)\n",
    "    ff_ext_datas[name].table_polysix = get_table_polysix(name,sinfo,grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,sinfo in sinfos_ext.items():\n",
    "    full_plot(sinfo.pr,name,sinfo,ai_data_ext[name],ff_ext_datas[name],save_png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing new QuickFF force field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def overlap_ffpars(ffp1,ffp2):\n",
    "    # Compare two force field parameter files and return the overlapping terms\n",
    "    # If second argument is a list, perform iteratively\n",
    "    assert isinstance(ffp1,str)\n",
    "    if isinstance(ffp2,list):\n",
    "        ref_ffp = copy.copy(ffp1)\n",
    "        for ffp in ffp2:\n",
    "            ref_ffp = overlap_ffpars(ref_ffp,ffp)\n",
    "        return ref_ffp\n",
    "    \n",
    "    elif isinstance(ffp2,str):\n",
    "        new_ffp = ''\n",
    "        diff = difflib.ndiff(ffp1.splitlines(keepends=True),ffp2.splitlines(keepends=True))\n",
    "        for s in diff:\n",
    "            if s[0]==' ': # no changes\n",
    "                new_ffp += s[2:]\n",
    "        return new_ffp\n",
    "    \n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "def extend_ffpars(ffp1,ffp2):\n",
    "    # Compare two force field parameter files and return both the overlap and the extensions\n",
    "    # If second argument is a list, perform iteratively\n",
    "    assert isinstance(ffp1,str)\n",
    "    if isinstance(ffp2,list):\n",
    "        ref_ffp = copy.copy(ffp1)\n",
    "        for ffp in ffp2:\n",
    "            ref_ffp = extend_ffpars(ref_ffp,ffp)\n",
    "        return ref_ffp\n",
    "    \n",
    "    elif isinstance(ffp2,str):\n",
    "        new_ffp = ''\n",
    "        diff = difflib.ndiff(ffp1.splitlines(keepends=True),ffp2.splitlines(keepends=True))\n",
    "        for s in diff:\n",
    "            if not s[0]=='?': # eye guides in diff\n",
    "                new_ffp += s[2:]\n",
    "        return new_ffp\n",
    "    \n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "def compare_structure_old(name,sinfo,old,new,ai,save_png=False):\n",
    "    structures = {'old':old, 'new':new, 'ai':ai}\n",
    "    compare_structures(name,sinfo.pr,sinfo.ff,structures,save_png=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the optimization\n",
    "for key,val in sinfo_triazine_groups.items():\n",
    "    print('{}: {}'.format(key,','.join(list(val.keys()))))\n",
    "\n",
    "    val_keys = list(val.keys())\n",
    "    print(val_keys)\n",
    "    sinfos = [val[k] for k in val_keys]  \n",
    "    sinfo = sinfos[0]\n",
    "\n",
    "    ffpars = sinfo.ff.ffpars\n",
    "    ffpars_nodih = overlap_ffpars(sinfo.ff.ffpars_nodih,[sinfo.ff.ffpars_nodih for sinfo in sinfos[1:]])\n",
    "    ffpars_polysix = extend_ffpars(sinfo.ff.ffpars_polysix,[sinfo.ff.ffpars_polysix for sinfo in sinfos[1:]])\n",
    "\n",
    "    pr_sub = Project(sinfo.get_sub_project_name(key,suffix='ffopt'))\n",
    "\n",
    "    yaff_opt_job(pr_sub, 'opt_old_ff', sinfo.ff.structure, sinfo.ff, ffpars)\n",
    "    yaff_opt_job(pr_sub, 'opt_new_ff', sinfo.ff.structure, sinfo.ff, ffpars_nodih + ffpars_polysix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare structures\n",
    "for key,val in sinfo_triazine_groups.items():\n",
    "    val_keys = list(val.keys())\n",
    "    print(val_keys)\n",
    "    sinfos = [val[k] for k in val_keys]  \n",
    "    sinfo = sinfos[0]\n",
    "\n",
    "    pr_sub = Project(sinfo.get_sub_project_name(key,suffix='ffopt'))\n",
    "    compare_structure_old(key,sinfo,pr_sub.load('opt_old_ff').get_structure(),pr_sub.load('opt_new_ff').get_structure(),sinfo.ff.structure,save_png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the optimization\n",
    "for key,val in sinfo_ext_groups.items():\n",
    "    print('{}: {}'.format(key,','.join(list(val.keys()))))\n",
    "\n",
    "    val_keys = list(val.keys())\n",
    "    print(val_keys)\n",
    "    sinfos = [val[k] for k in val_keys]  \n",
    "    sinfo = sinfos[0]\n",
    "\n",
    "    ffpars = sinfo.ff.ffpars\n",
    "    ffpars_nodih = overlap_ffpars(sinfo.ff.ffpars_nodih,[sinfo.ff.ffpars_nodih for sinfo in sinfos[1:]])\n",
    "    ffpars_polysix = extend_ffpars(sinfo.ff.ffpars_polysix,[sinfo.ff.ffpars_polysix for sinfo in sinfos[1:]])\n",
    "\n",
    "    pr_sub = Project(sinfo.get_sub_project_name(key,suffix='ffopt'))\n",
    "\n",
    "    yaff_opt_job(pr_sub, 'opt_old_ff', sinfo.ff.structure, sinfo.ff, ffpars)\n",
    "    yaff_opt_job(pr_sub, 'opt_new_ff', sinfo.ff.structure, sinfo.ff, ffpars_nodih + ffpars_polysix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare structures\n",
    "for key,val in sinfo_ext_groups.items():\n",
    "    val_keys = list(val.keys())\n",
    "    print(val_keys)\n",
    "    sinfos = [val[k] for k in val_keys]  \n",
    "    sinfo = sinfos[0]\n",
    "\n",
    "    pr_sub = Project(sinfo.get_sub_project_name(key,suffix='ffopt'))\n",
    "    compare_structure_old(key,sinfo,pr_sub.load('opt_old_ff').get_structure(),pr_sub.load('opt_new_ff').get_structure(),sinfo.ff.structure,save_png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing clean QuickFF force field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return array with terms and their values\n",
    "def read_pars_cov(fn):\n",
    "    terms = [\"BONDHARM:PARS\", \"BENDAHARM:PARS\", \"BENDCLIN:PARS\", \"BENDCOS:PARS\", \"TORSION:PARS\", \"TORSCPOLYSIX:PARS\", \"OOPDIST:PARS\", \"SQOOPDIST:PARS\", \"Cross:PARS\"]\n",
    "    \n",
    "    # Assume covalent parameters always have the correct header\n",
    "    \n",
    "    bondharm  = []\n",
    "    bendharm  = []\n",
    "    bendclin  = []\n",
    "    bendcos   = []\n",
    "    torsion   = []\n",
    "    torscpoly = []\n",
    "    oopdist   = []\n",
    "    sqoopdist = []\n",
    "    cross     = []\n",
    "        \n",
    "    with open(fn, 'r') as f:\n",
    "        text = f.read()\n",
    "        split = text.split()\n",
    "\n",
    "        for i in range(len(split)):\n",
    "            if(split[i] == terms[0]):\n",
    "                bondharm.append(add_term(split, [i+1, i+2], [i+3], [i+4]))    \n",
    "            elif(split[i] == terms[1]):\n",
    "                bendharm.append(add_term(split, [i+1, i+2, i+3], [i+4], [i+5]))\n",
    "            elif(split[i] == terms[2]):\n",
    "                bendclin.append(add_term(split, [i+1, i+2, i+3], [i+4]))    \n",
    "            elif(split[i] == terms[3]):\n",
    "                bendcos.append(add_term(split, [i+1, i+2, i+3], [i+5], [i+6], index_mult=i+4))    \n",
    "            elif(split[i] == terms[4]):\n",
    "                torsion.append(add_term(split, [i+1, i+2, i+3, i+4], [i+6], [i+7], index_mult=i+5))\n",
    "            elif(split[i] == terms[5]):\n",
    "                torscpoly.append(add_term(split, [i+1, i+2, i+3, i+4], [i+5, i+6, i+7, i+8, i+9, i+10]))    \n",
    "            elif(split[i] == terms[6]):\n",
    "                oopdist.append(add_term(split, [i+1, i+2, i+3, i+4], [i+5], [i+6]))\n",
    "            elif(split[i] == terms[7]):\n",
    "                sqoopdist.append(add_term(split, [i+1, i+2, i+3, i+4], [i+5], [i+6]))\n",
    "            elif(split[i] == terms[8]):\n",
    "                cross.append(add_term(split, [i+1, i+2, i+3], [i+4, i+5, i+6], [i+7, i+8, i+9]))             \n",
    "    \n",
    "    dic = []\n",
    "    dic.append(bondharm)\n",
    "    dic.append(bendharm)\n",
    "    dic.append(bendclin)\n",
    "    dic.append(bendcos)\n",
    "    dic.append(torsion)\n",
    "    dic.append(torscpoly)\n",
    "    dic.append(oopdist)\n",
    "    dic.append(sqoopdist)\n",
    "    dic.append(cross)\n",
    "    \n",
    "    return dic\n",
    "   \n",
    "# return array with terms and their values\n",
    "def read_pars_ei(fn,units,scales,dielectric):\n",
    "    terms_ei = [\"FIXQ:ATOM\", \"FIXQ:BOND\"]\n",
    "    terms_header = [\"FIXQ:UNIT\",\"FIXQ:SCALE\",\"FIXQ:DIELECTRIC\"]\n",
    "    \n",
    "    atomcharge = []\n",
    "    bondcharge = []\n",
    "        \n",
    "    with open(fn, 'r') as f:\n",
    "        text = f.read()\n",
    "        split = text.split()\n",
    "        \n",
    "        for i in range(len(split)):\n",
    "            if(split[i] == terms_ei[0]):\n",
    "                atomcharge.append(add_term(split, [i+1], [i+2, i+3]))    \n",
    "            elif(split[i] == terms_ei[1]):\n",
    "                bondcharge.append(add_term(split, [i+1, i+2], [i+3]))\n",
    "            elif(split[i] == terms_header[0]):\n",
    "                units[split[i+1]] = split[i+2]\n",
    "            elif(split[i] == terms_header[1]):\n",
    "                scales[int(split[i+1])] = float(split[i+2]) \n",
    "            elif(split[i] == terms_header[1]):\n",
    "                dielectric = float(split[i+1])    \n",
    "            \n",
    "            \n",
    "    dic = []\n",
    "    dic.append(atomcharge)\n",
    "    dic.append(bondcharge)\n",
    "    return dic\n",
    "\n",
    "\n",
    "# return array with terms and their values\n",
    "def read_pars_vdw(fn,units,scales):\n",
    "    vdws = {'mm3':[],'mm3cap':[],'lj':[]}\n",
    "    terms_vdw = [\"MM3:PARS\", \"MM3CAP:PARS\", \"LJ:PARS\"]\n",
    "    terms_header = [\"MM3:UNIT\",\"MM3CAP:UNIT\",\"LJ:UNIT\",\"MM3:SCALE\",\"MM3CAP:SCALE\",\"LJ:SCALE\"]\n",
    "    \n",
    "    mm3 = []\n",
    "    mm3cap = []\n",
    "    lj = []\n",
    "        \n",
    "    with open(fn, 'r') as f:\n",
    "        text = f.read()\n",
    "        split = text.split()\n",
    "        \n",
    "        for i in range(len(split)):\n",
    "            if(split[i] == terms_vdw[0]):\n",
    "                vdws['mm3'].append(add_term(split, [i+1], [i+2, i+3, i+4]))\n",
    "            elif(split[i] == terms_vdw[1]):\n",
    "                vdws['mm3cap'].append(add_term(split, [i+1], [i+2, i+3, i+4]))\n",
    "            elif(split[i] == terms_vdw[2]):\n",
    "                vdws['lj'].append(add_term(split, [i+1], [i+2, i+3]))\n",
    "            elif(split[i] in terms_header[0:3]):\n",
    "                units[split[i+1]] = split[i+2]\n",
    "            elif(split[i] in terms_header[3:]):\n",
    "                scales[int(split[i+1])] = float(split[i+2])       \n",
    "    \n",
    "    lengths = [len(v) for v in vdws.values()]\n",
    "    assert max(lengths)==sum(lengths) # check that only one of them is used\n",
    "    \n",
    "    key = list(vdws.keys())[np.argmax(lengths)]\n",
    "    return vdws[key],key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_separate_pars_file(fns, blocks, max_length, ei_units, ei_scales, dielectric, vdw_units, vdw_scales, vdw_key='mm3'):\n",
    "    cov_values = blocks[0]\n",
    "    ei_values = blocks[1]\n",
    "    vdw_values = blocks[2]\n",
    "    \n",
    "    with open(fns[0], 'w') as f:            \n",
    "        \n",
    "        # Write covalent part\n",
    "        f.write(\"# BONDHARM\\n#---------\\nBONDHARM:UNIT  K kjmol/A**2\\nBONDHARM:UNIT  R0 A\\n\\n\")\n",
    "        for pair in cov_values[0]:\n",
    "            f.write(\"BONDHARM:PARS  \")\n",
    "            f.write(\"{:>{w}}  {:>{w}}  {: 1.10e}  {: 1.10e}\".format(pair[0][0], pair[0][1], float(pair[1][0]), float(pair[2][0]), w=max_length))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"# BENDAHARM\\n#----------\\nBENDAHARM:UNIT  K kjmol/rad**2\\nBENDAHARM:UNIT  THETA0 deg\\n\\n\")\n",
    "        for pair in cov_values[1]:\n",
    "            f.write(\"BENDAHARM:PARS  \")\n",
    "            f.write(\"{:>{w}}  {:>{w}}  {:>{w}}  {: 1.10e}  {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], float(pair[1][0]), float(pair[2][0]), w=max_length))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        if cov_values[2]:  #check whether there is anything in this list   \n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(\"# BENDCLIN\\n#----------\\nBENDCLIN:UNIT  A kjmol\\n\\n\")\n",
    "            for pair in cov_values[2]:\n",
    "                f.write(\"BENDCLIN:PARS  \")\n",
    "                f.write(\"{:>{w}}  {:>{w}}  {:>{w}}  {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], float(pair[1][0]), w=max_length))\n",
    "                f.write('\\n')\n",
    "                \n",
    "        if cov_values[3]:  #check whether there is anything in this list   \n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(\"# BENDCOS\\n#----------\\nBENDCOS:UNIT  A kjmol\\nBENDCOS:UNIT PHI0 deg\\n\\n\")\n",
    "            for pair in cov_values[3]:\n",
    "                f.write(\"BENDCOS:PARS  \")\n",
    "                f.write(\"{:>{w}}  {:>{w}}  {:>{w}} {} {: 1.10e} {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], int(pair[3]), float(pair[1][0]), float(pair[2][0]), w=max_length))\n",
    "                f.write('\\n')\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"# TORSION\\n#--------\\nTORSION:UNIT  A kjmol\\nTORSION:UNIT  PHI0 deg\\n\\n\")\n",
    "        \n",
    "        for pair in cov_values[4]:\n",
    "            f.write(\"TORSION:PARS  \")\n",
    "            f.write(\"{:>{w}}  {:>{w}}  {:>{w}}  {:>{w}}  {} {: 1.10e}  {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], pair[0][3], int(pair[3]), float(pair[1][0]), float(pair[2][0]), w=max_length))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        if cov_values[5]:  #check whether there is anything in this list\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(\"# TORSCPOLYSIX\\n#--------\\nTORSCPOLYSIX:UNIT  C1 kjmol\\nTORSCPOLYSIX:UNIT  C2 kjmol\\nTORSCPOLYSIX:UNIT  C3 kjmol\\nTORSCPOLYSIX:UNIT  C4 kjmol\\nTORSCPOLYSIX:UNIT  C5 kjmol\\nTORSCPOLYSIX:UNIT  C6 kjmol\\n\\n\")\n",
    "\n",
    "            for pair in cov_values[5]:\n",
    "                f.write(\"TORSCPOLYSIX:PARS  \")\n",
    "                f.write(\"{:>{w}}  {:>{w}}  {:>{w}}  {:>{w}}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], pair[0][3], float(pair[1][0]), float(pair[1][1]), float(pair[1][2]), float(pair[1][3]), float(pair[1][4]), float(pair[1][5]), w=max_length))\n",
    "                f.write('\\n')\n",
    "        \n",
    "        if cov_values[6]:  #check whether there is anything in this list\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(\"# OOPDIST\\n#--------\\nOOPDIST:UNIT  K kjmol/A**2\\nOOPDIST:UNIT  D0 A\\n\\n\")\n",
    "\n",
    "            for pair in cov_values[6]:\n",
    "                f.write(\"OOPDIST:PARS  \")\n",
    "                f.write(\"{:>{w}}  {:>{w}}  {:>{w}}  {:>{w}}  {: 1.10e}  {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], pair[0][3], float(pair[1][0]), float(pair[2][0]), w=max_length))\n",
    "                f.write('\\n')\n",
    "        \n",
    "        if cov_values[7]:  #check whether there is anything in this list\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(\"# SQOOPDIST\\n#--------\\nSQOOPDIST:UNIT  K kjmol/A**4\\nSQOOPDIST:UNIT  D0 A**2\\n\\n\")\n",
    "\n",
    "            for pair in cov_values[7]:\n",
    "                f.write(\"SQOOPDIST:PARS  \")\n",
    "                f.write(\"{:>{w}}  {:>{w}}  {:>{w}}  {:>{w}}  {: 1.10e}  {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], pair[0][3], float(pair[1][0]), float(pair[2][0]), w=max_length))\n",
    "                f.write('\\n')\n",
    "\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"# Cross\\n#------\\nCross:UNIT  KSS kjmol/angstrom**2\\nCross:UNIT  KBS0 kjmol/(angstrom*rad)\\nCross:UNIT  KBS1 kjmol/(angstrom*rad)\\nCross:UNIT  R0 angstrom\\nCross:UNIT  R1 angstrom\\nCross:UNIT  THETA0 deg\\n\\n\")\n",
    "\n",
    "        for pair in cov_values[8]:\n",
    "            f.write(\"CROSS:PARS  \")\n",
    "            f.write(\"{:>{w}}  {:>{w}}  {:>{w}}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}  {: 1.10e}\".format(pair[0][0], pair[0][1], pair[0][2], float(pair[1][0]), float(pair[1][1]), float(pair[1][2]), float(pair[2][0]), float(pair[2][1]), float(pair[2][2]), w=max_length))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "    with open(fns[1], 'w') as f:  \n",
    "        \n",
    "        # Write ei part\n",
    "        f.write(\"#Fixed charges\\n#---------------\\n\\n\")\n",
    "        f.write(\"\".join([\"FIXQ:UNIT {} {}\\n\".format(k,v) for k,v in ei_units.items()]) + \"\".join([\"FIXQ:SCALE {} {}\\n\".format(k,v) for k,v in ei_scales.items()]) + \"FIXQ:DIELECTRIC {}\\n\\n\".format(dielectric))\n",
    "        f.write(\"# Atomic parameters\\n# ----------------------------------------------------\\n# KEY        label  Q_0A              R_A\\n# ----------------------------------------------------\\n\")\n",
    "        for pair in ei_values[0]:\n",
    "            f.write(\"FIXQ:ATOM \")\n",
    "            f.write(\"{:>{w}}  {: 1.10f}  {: 1.10f}\".format(pair[0][0], float(pair[1][0]), float(pair[1][1]), w=max_length))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        f.write(\"# Bond parameters\\n# ----------------------------------------------------\\n# KEY         label0   label1           P_AB\\n# ----------------------------------------------------\\n\")\n",
    "        for pair in ei_values[1]:\n",
    "            f.write(\"FIXQ:BOND  \")\n",
    "            f.write(\"{:>{w}}  {:>{w}}  {: 1.10f}\".format(pair[0][0], pair[0][1], float(pair[1][0]), w=max_length))\n",
    "            f.write('\\n')\n",
    "            \n",
    "    with open(fns[2], 'w') as f:\n",
    "        \n",
    "        # Write VDW part\n",
    "        f.write(\"# van der Waals\\n#---------------\\n# The following mathemetical form is supported:\\n#  - MM3(CAP):   EPSILON*(1.84e5*exp(-12*r/SIGMA)-2.25*(SIGMA/r)^6)\\n#  - LJ:    4.0*EPSILON*((SIGMA/r)^12 - (SIGMA/r)^6)\\n\\n\")\n",
    "        if vdw_key=='mm3':\n",
    "            f.write(\"\".join([\"MM3:UNIT {} {}\\n\".format(k,v) for k,v in vdw_units.items()]) + \"\".join([\"MM3:SCALE {} {}\\n\".format(k,v) for k,v in vdw_scales.items()]))\n",
    "            f.write(\"\\n# ---------------------------------------------\\n# KEY      ffatype    SIGMA  EPSILON  ONLYPAULI\\n# ---------------------------------------------\\n\")\n",
    "            for pair in vdw_values:\n",
    "                f.write(\"MM3:PARS \")\n",
    "                f.write(\"{:>{w}}  {:1.4f}  {:1.4f}  {}\".format(pair[0][0], float(pair[1][0]), float(pair[1][1]), int(pair[1][2]), w=max_length))\n",
    "                f.write('\\n')\n",
    "        elif vdw_key=='mm3cap':\n",
    "            f.write(\"\".join([\"MM3CAP:UNIT {} {}\\n\".format(k,v) for k,v in vdw_units.items()]) + \"\".join([\"MM3CAP:SCALE {} {}\\n\".format(k,v) for k,v in vdw_scales.items()]))\n",
    "            f.write(\"\\n# ---------------------------------------------\\n# KEY      ffatype    SIGMA  EPSILON  ONLYPAULI\\n# ---------------------------------------------\\n\")\n",
    "            for pair in vdw_values:\n",
    "                f.write(\"MM3CAP:PARS \")\n",
    "                f.write(\"{:>{w}}  {:1.4f}  {:1.4f}  {}\".format(pair[0][0], float(pair[1][0]), float(pair[1][1]), int(pair[1][2]), w=max_length))\n",
    "                f.write('\\n')\n",
    "        elif vdw_key=='lj':\n",
    "            f.write(\"\".join([\"LJ:UNIT {} {}\\n\".format(k,v) for k,v in vdw_units.items()]) + \"\".join([\"LJ:SCALE {} {}\\n\".format(k,v) for k,v in vdw_scales.items()]))\n",
    "            f.write(\"# ---------------------------------------------\\n# KEY      ffatype    SIGMA  EPSILON\\n# ---------------------------------------------\\n\")\n",
    "            for pair in vdw_values:\n",
    "                f.write(\"LJ:PARS \")\n",
    "                f.write(\"{:>{w}}  {:1.4f}  {:1.4f}\".format(pair[0][0], float(pair[1][0]), float(pair[1][1]), w=max_length))\n",
    "                f.write('\\n')   \n",
    "        else:\n",
    "            raise ValueError('Key not recognized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_separate_ffpars(sinfo_groups,name_function=None):\n",
    "    \"\"\"\n",
    "        Create separated ffpars files in its contributions (cov,ei,vdw)\n",
    "        Unique ffpars will be created per key in sinfo_groups\n",
    "        if for a single block there are multiple keys\n",
    "    \"\"\"\n",
    "    block_names = []\n",
    "    for key,val in sinfo_groups.items():\n",
    "        sinfos = [val[k] for k in val.keys()]  \n",
    "        sinfo = sinfos[0]\n",
    "        block_names.append(sinfo.ff.block_name)\n",
    "        \n",
    "    c = Counter(block_names)\n",
    "    \n",
    "    for key,val in sinfo_groups.items():\n",
    "        print('{}: {}'.format(key,','.join(list(val.keys()))))\n",
    "\n",
    "        val_keys = list(val.keys())\n",
    "        #print(val_keys)\n",
    "        sinfos = [val[k] for k in val_keys]  \n",
    "        sinfo = sinfos[0]\n",
    "        \n",
    "        pr_sub_name = sinfo.get_sub_project_name(key,suffix='ffopt')\n",
    "        print(pr_sub_name)\n",
    "\n",
    "        pr_sub = Project(pr_sub_name)\n",
    "        opt_job = pr_sub.load('opt_new_ff') \n",
    "\n",
    "        # Get the parameter file of the opt job\n",
    "        fn_ffpars = os.path.join(opt_job.working_directory, 'pars.txt')\n",
    "\n",
    "        # Read the separate ffpars contributions\n",
    "        ei_units,ei_scales,vdw_units,vdw_scales = {},{},{},{}\n",
    "        dielectric = 1.0\n",
    "\n",
    "        cov_block = read_pars_cov(fn_ffpars)\n",
    "        ei_block = read_pars_ei(fn_ffpars,ei_units,ei_scales,dielectric)\n",
    "        vdw_block, vdw_key = read_pars_vdw(fn_ffpars,vdw_units,vdw_scales)\n",
    "\n",
    "        # Get max atype length\n",
    "        if len(ei_block[0]) > 0:\n",
    "            max_length = max([len(pair[0][0]) for pair in ei_block[0]])\n",
    "        elif len(vdw_block) > 0:\n",
    "            max_length = max([len(pair[0][0]) for pair in vdw_block])\n",
    "        else:\n",
    "            raise ValueError\n",
    "        #print(max_length)\n",
    "\n",
    "        # Write pars file\n",
    "        path = sinfo.pr.root_path +  sinfo.pr.project_path.split('/')[0] + '/input_files/' + '/'.join(sinfo.pr.project_path.split('/')[1:]) + sinfo.ff.block_name + '/new_ffpars/'\n",
    "        \n",
    "        if c[sinfo.ff.block_name]>1:\n",
    "            assert name_function is not None\n",
    "            path = path + '{}/'.format(name_function(key))\n",
    "        pathlib.Path(path).mkdir(parents=True, exist_ok=True) # make directory if it does not exist\n",
    "\n",
    "        fns = [path + 'pars_{}.txt'.format(bl) for bl in ['cov','ei','vdw']]\n",
    "        print_separate_pars_file(fns, [cov_block,ei_block,vdw_block], max_length, ei_units, ei_scales, dielectric, vdw_units, vdw_scales, vdw_key=vdw_key)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_separate_ffpars(sinfo_triazine_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_separate_ffpars(sinfo_ext_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
